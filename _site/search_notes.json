[
  
    {

      "title"    : "Home",
      "url"      : "/notes/000-Home",
      "category" : "",
      "tags"     : "",
      "content"  : "Here where I will be linking everything together\n\nArea of Interest\n\n\n  [[010 Productivity]]\n  [[020 Knowledgebase]]\n  [[030 Research]]\n  [[040 Projects]]\n  [[050 School]]\n\n\nHighlights\n\n\n  [[100 Interesting Quotes]]"

    } ,
  
    {

      "title"    : "010 Productivity",
      "url"      : "/notes/010-Productivity",
      "category" : "",
      "tags"     : "",
      "content"  : "[[000 Home]]"

    } ,
  
    {

      "title"    : "020 Knowledgebase",
      "url"      : "/notes/020-Knowledgebase",
      "category" : "",
      "tags"     : "",
      "content"  : "[[000 Home]]"

    } ,
  
    {

      "title"    : "030 Research",
      "url"      : "/notes/030-Research",
      "category" : "",
      "tags"     : "",
      "content"  : "[[000 Home]]"

    } ,
  
    {

      "title"    : "040 Projects",
      "url"      : "/notes/040-Projects",
      "category" : "",
      "tags"     : "",
      "content"  : "[[000 Home]]"

    } ,
  
    {

      "title"    : "050 School",
      "url"      : "/notes/050-School",
      "category" : "",
      "tags"     : "",
      "content"  : "[[000 Home]]\n\n\n  [[Matrix Analysis]]\n  [[Natural Language Processing]]\n  [[Convex Optimization]]\n  [[Machine Learning]]\n  [[Digital Image Processing]]"

    } ,
  
    {

      "title"    : "110 Interesting Quotes",
      "url"      : "/notes/100-Interesting-Quotes",
      "category" : "",
      "tags"     : "",
      "content"  : "[[000 Home]]\n\nCareer\n\n\n  [[IQ Success]]\n  [[IQ Programming]]"

    } ,
  
    {

      "title"    : "Anki",
      "url"      : "/notes/Anki",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Career",
      "url"      : "/notes/Career",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]\n\n\n  Negotiation: [[202101140846]]"

    } ,
  
    {

      "title"    : "Computer Science",
      "url"      : "/notes/Computer-Science",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Computer Vision",
      "url"      : "/notes/Computer-Vision",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Data Science",
      "url"      : "/notes/Data-Science",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Data or Machine Engineering",
      "url"      : "/notes/Data-or-Machine-Engineering",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Economy",
      "url"      : "/notes/Economy",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Git",
      "url"      : "/notes/Git",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "IQ Programming",
      "url"      : "/notes/IQ-Programming",
      "category" : "",
      "tags"     : "",
      "content"  : "[[110 Interesting Quotes]] [[Programming]]\n\n\n  Dependencies (coupling) is an important concern to address, but it's only 1 of 4 criteria that I consider and it's not the most important one. I try to optimize my code around reducing state, coupling, complexity and code, in that order. I'm willing to add increased coupling if it makes my code more stateless. I'm willing to make it more complex if it reduces coupling. And I'm willing to duplicate code if it makes the code less complex. Only if it doesn't increase state, coupling or complexity do I setup code. The reason I put stateless code as the highest priority is it's the easiest to reason about. Stateless logic functions the same whether run normally, in parallel or distributed. It's the easiest to test, since it requires very little setup code. And it's the easiest to scale up, since you just run another copy of it. Once you introduce state, your life gets significantly harder. I think the reason that novice programmers optimize around code reduction is that it's the easiest of the 4 to spot. The other 3 are much more subtle and subjective and so will require greater experience to spot. But learning those priorities, in that order, has made me a significantly better developer.\n    \n      \"The best programs are the ones written when the programmer is supposed to be working on something else.\" - Melinda Varian.\n    \n  \n  \"Colab or didn't happen…\" - @jesseengel\n  \"When people say \"I am investing for the long term\", it means they are losing money.\" - @nntaleb\n  \"round-robin fashion\" - Fuxin Li\n  \"i took this writing class in university, where an author came to talk to the class. someone asked him why he has to publish his writing, instead of just writing for himself. he was gross, and he said that writing for yourself is like masturbating and publishing is like having sex. and this has stuck with me for about 10 years.\" - http://blog.spencermounta.in/2018/how-to-be-a-blog-in-2018/index.html\n  \"If you torture data long enough, it will confess to anything.\" - https://www.reddit.com/r/statistics/comments/k9e43a/question_is_this_just_bad_statistics/gf3pwfi/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3\n  \"The will to win is not nearly as important as the will to prepare to win. Everyone wants to win, but not everyone wants to prepare to win.\" - Bobby Knight"

    } ,
  
    {

      "title"    : "IQ Success",
      "url"      : "/notes/IQ-Success",
      "category" : "",
      "tags"     : "",
      "content"  : "[[110 Interesting Quotes]] [[Success]]\n\n\n  This guy has gone to the zoo and interviewed all the animals. The tiger says that the secret to success is to live alone, be well disguised, have sharp claws and know how to stalk. The snail says that the secret is to live inside a solid shell, stay small, hide under dead trees and move slowly around at night. The parrot says that success lies in eating fruit, being alert, packing light, moving fast by air when necessary, and always sticking by your friends. His conclusion: These animals are giving contradictory advice! And that's because they're all \"outliers\".\n    \n      But both of these points are subtly misleading. Yes, the advice is contradictory, but that's only a problem if you imagine that the animal kingdom is like a giant arena in which all the world's animals battle for the Animal Best Practices championship [1], after which all the losing animals will go extinct and the entire world will adopt the winning ways of the One True Best Animal. But, in fact, there are a hell of a lot of different ways to be a successful animal, and they coexist nicely. Indeed, they form an ecosystem in which all animals require other, much different animals to exist. https://news.ycombinator.com/item?id=469831#up_469940\n    \n  \n  \"The difference between successful people and really successful people is that really successful people say no to almost everything.\" - Warren Buffett\n  \"People think focus means saying yes to the thing you've got to focus on. But that's not what it means at all. It means saying no to the hundred other good ideas that there are. You have to pick carefully. I'm actually as proud of the things we haven't done as the things I have done. Innovation is saying no to 1,000 things.\" - Steve Jobs\n  \"You've gotta keep control of your time and you can't unless you say no. You can't let people set your agenda in life.\" - Warren Buffett"

    } ,
  
    {

      "title"    : "Learning",
      "url"      : "/notes/Learning",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Life",
      "url"      : "/notes/Life",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Machine Learning",
      "url"      : "/notes/Machine-Learning",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Mathematics",
      "url"      : "/notes/Mathematics",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Matrix Analysis",
      "url"      : "/notes/Matrix-Analysis",
      "category" : "",
      "tags"     : "",
      "content"  : "[[Machine Learning]] [[Signal Processing]] [[Mathematics]]\n\nLecture Notes\n\n\n  0: [[202101101808]]\n  1:\n  2:\n\n\nReading Notes\n\n\n  Matrix Analysis\n  Matrix Computations\n  ECE 712 Course Notes"

    } ,
  
    {

      "title"    : "Natural Language Processing",
      "url"      : "/notes/Natural-Language-Processing",
      "category" : "",
      "tags"     : "",
      "content"  : "[[Machine Learning]]"

    } ,
  
    {

      "title"    : "Obsidian",
      "url"      : "/notes/Obsidian",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Physics",
      "url"      : "/notes/Physics",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Privacy",
      "url"      : "/notes/Privacy",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Productivity",
      "url"      : "/notes/Productivity",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "PyTorch",
      "url"      : "/notes/PyTorch",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Research",
      "url"      : "/notes/Research",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Software Engineering",
      "url"      : "/notes/Software-Engineering",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Random Notes",
      "url"      : "/notes/Startup",
      "category" : "",
      "tags"     : "",
      "content"  : "[[000 Home]]\n\n\n  Tracking your storage: [[202101140815  —]]"

    } ,
  
    {

      "title"    : "Statistics",
      "url"      : "/notes/Statistics",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "Writing",
      "url"      : "/notes/Writing",
      "category" : "",
      "tags"     : "",
      "content"  : "[[020 Knowledgebase]]"

    } ,
  
    {

      "title"    : "5 important features of Obsidian and how I implemented a Zettelkasten workflow!",
      "url"      : "/notes/202101081516",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Obsidian]]\n\n\n  Zettelkasten method\n    \n      take literature notes -&gt; removed from Obsidian\n      take reference notes -&gt; source note\n      create permanent notes\n      review notes\n    \n  \n  know how to move stuff from Obsidian to Anki automatically using some script or plugin\n    \n      what I want is the ability to import my notes into anki\n      [[file^type a sentence | rename it]]"

    } ,
  
    {

      "title"    : "What would you do differently if you were in your latter years of college (junior-senior)",
      "url"      : "/notes/202101100831",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Data Science]] [[Career]]\n\n\n  Not be content with mediocre projects but actually build and research something meaningful.\n  Build relationships and network for potential careers.\n  Internships\n  cozy up with a favorite professor or two\n  Market yourself\n  build projects\n  Be ready to make the step into career as smooth as possible.\n  Learn it so it sticks rather than cramming for exams\n  Take math and statistics classes more seriously!\n  Find a professor to do research with"

    } ,
  
    {

      "title"    : "How do you avoid answering cloze cards without first thinking about the answer ?",
      "url"      : "/notes/202101101016",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Anki]]\n\n\n  problem: remembering cloze setup rather than what is being asked in the question, aka cheating\n  helpful tips\n    \n      keep the card simple, no a lot of text, just atomic idea\n        \n          this might not work for proofs as you will need to understand what is the proof actually stating rather than memorizing the text. Hence, try to include a short answer of the proof and supplement links for the actual proof\n          for the proof, you can use cloze to know what is the next step of the proof (answer)\n        \n      \n      card interval is too short, wait for longer time and it won't be easy\n      card numbers is too small\n    \n  \n  cloze surrounding information\n    \n      ex:\n        \n          bad: Every {{c1::Tuesday}} the sky is blue but every {c1::Friday}} it is red.\n          good: Every {{c1::Tuesday}} the sky is {{c1::blue}} but every {{c2::Friday}} it is {{c2::red}}.\n        \n      \n      you won't memorize the surrounding information of the needed question\n    \n  \n  reformulate the problems\n    \n      before: {{c1::X}} is a symptom of disease Y\n      after: Disease Y has {{c1::X}} as a symptom"

    } ,
  
    {

      "title"    : "How to take smart notes",
      "url"      : "/notes/202101101031",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Learning]] [[Obsidian]] [[People]]\n\n\n  \"[Notes] aren't a record of my thinking process. They are my thinking process.\" - [[Richard Feynman]]\n  \"Notes on paper, or on a computer screen […] do not make contemporary physics or other kinds of intellectual endeavor easier, they make it possible\" - [[Neil Levy]]\n  [[Niklas Luhmann]], the creator of Zettelkasten\n  \" I only do what is easy\" - [[Niklas Luhmann]]\n  ~ 6 notes a day\n  Note types:\n    \n      Literature notes\n        \n          what is said\n          source\n        \n      \n      Reading notes\n        \n          his actual ideas of the literature notes\n          what it does this mean\n          he writes in a way that anyone can understand it, not only himself\n        \n      \n    \n  \n  Writing process\n    \n      find a topic/research-question (brainstorming)\n      research/find literature\n      read and take notes\n      draw conclusions/outline text\n      write\n      hit or miss your deadline\n      start all over with the next project\n    \n  \n  The actual productivity\n    \n      Thinking, connecting, and understanding\n      Focus on the process (not the outcome)\n      Writing is broken down into reasonable steps (one note at a time)\n        \n          write 3-6 notes a day\n        \n      \n      The value of each idea compounds (more notes, better)\n        \n          connect all notes rather than storing in in an archive\n        \n      \n      Clear distinction between permanent and temporary notes\n        \n          everything in an inbox and check whether they are required to add to your set of notes or not - [[Getting Things Done]]\n        \n      \n    \n  \n  the actual learning (is - not)\n    \n      spacing - cramming\n        \n          flashcards (anki), issue no context\n        \n      \n      interleaving - one thing at a time\n        \n          baby steps, start easy and increase difficulty\n        \n      \n      connecting - compartmentalization\n      self-testing - underlining and copying\n        \n          test your knowledge\n        \n      \n      elaboration - re-reading\n        \n          when re-reading, it feels familiar so we think that it is productive. However, it isn't.\n          elaboration, ask questions about what you came across\n            \n              what is it about?\n              what does it mean for…?\n              how does it connect with…?\n              swapping perspectives: from the context of the source to the context of ones own thoughts\n                \n                  from my point-of-view, why this is important and useful?\n                \n              \n              does it contradict, complement, confirm or specify what I believed before?\n            \n          \n        \n      \n      creativity, it doesn't happen suddenly. It needs time and focus\n      further reading\n        \n          [[How to Take Smart Notes]]\n          [[Make it Stick]]\n        \n      \n      \"real expertise don't make plans, they make inform decision for the given situation that they are in\" - some scientist"

    } ,
  
    {

      "title"    : "How genius are made: Niklas Luhmann&#39;s zettelkasten and how to be creative and productive in thinking",
      "url"      : "/notes/202101101206",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[People]] [[Zettelkasten]] [[Learning]] [[Niklas Luhmann]]\n\n\n  [[Niklas Luhmann]] has published more than 400 papers and 50 books, and he has more than 200 papers that were archived\n  his phases\n    \n      reading and note-taking\n        \n          notes are sparse and condense\n        \n      \n      Rewrite for zettelkasten (transferring the notes), every evening of the day\n        \n          what topics does the notes belong to?\n          combine with old notes with the same topic\n          then he transfer his notes into a new zettel to fit into his zettel structure of cards of the same topic\n        \n      \n      adding and structuring zettels\n        \n          reformulating the cards\n          add questions and answer them\n          what topics belong to each others? (hub notes). He links the hub notes with an introduction to a topic\n            \n              e.g.\n                \n                  list of topics that are related, link zettel notes that introduce the topic\n                \n              \n            \n          \n          kept an overall index of all interesting words that he will need to look into\n            \n              Arabic 45, 89, ed (introduce to the word)\n            \n          \n        \n      \n      ask questions\n        \n          he asks questions and link the zettels as a answer\n          he uses this to select certain questions and zettels to publish about something\n        \n      \n    \n  \n  What can we do?\n    \n      gather input and take notes\n      transfer notes to storage\n      frequently go through notes\n        \n          add thoughts\n          structure notes"

    } ,
  
    {

      "title"    : "Lecture 0",
      "url"      : "/notes/202101101808",
      "category" : "",
      "tags"     : "slides",
      "content"  : "[[Matrix Analysis]]\n\nCourse\n\n\n  Structure of the course\n    \n      W1: basic matrix concepts, subspace, norms\n      W2: [[Linear Least Squares]] (LS)\n      W3: [[Eigendecomposition]]\n        \n          PageRank\n        \n      \n      W4: [[Singular Value Decomposition]]\n      W5 [[Positive Semidefinite Matrices]]\n      W6: [[Linear System of Equations]]\n        \n          other form of LS\n        \n      \n      W7: [[Compressive Matrix Sensing]]\n        \n          new\n        \n      \n      W8: [[Nonnegative Factorization]]\n        \n          core topic\n        \n      \n      W9: [[Tensor Decomposition]]\n        \n          high dimension linear algebra\n        \n      \n    \n  \n  Learning Resources\n    \n      [[Matrix Computations by Golub]] MUST\n        \n          use as a dictionary\n          how to decompose matrix algorithms\n          for math\n          go-to book for matrix for Machine Learning and Signal Processing\n        \n      \n      [[Matrix Analysis by Horn]]\n        \n          for math\n          explains theory\n        \n      \n      [[ECE 712 Course Notes by Reilly]]\n        \n          for engineers\n          more about Signal Processing applications (detailed)\n        \n      \n    \n  \n\n\n[[Least Squares]] (LS)\n\n\n  Problem: given A (mxn), y (n), solve\n\\(\\min _{\\mathbf{x} \\in \\mathbb{R}^{n}}\\|\\mathbf{y}-\\mathbf{A} \\mathbf{x}\\|_{2}^{2}\\)\n  Eucildean norm:\n\\(\\|\\mathbf{x}\\|_{2}=\\sqrt{\\sum_{i=1}^{n}\\left|x_{i}\\right|^{2}}\\)\n  Assuming a tall and full-rank A, the LS solution is uniquely given by: - closed-form solution?\n\\(\\mathbf{x}_{\\mathrm{LS}}=\\left(\\mathbf{A}^{T} \\mathbf{A}\\right)^{-1} \\mathbf{A}^{T} \\mathbf{y}\\)\n\n\nAutoregression (AR) model\n\n\n  Application example: Linear Prediction\n\\(y[n]=a_{1} y[n-1]+a_{2} y[n-2]+\\cdots+a_{L} y[n-L]+w[n]\\)\n  $\\left{a_{i}\\right}_{i=1}^{L}$ are some coefficients\n  $w[n]$ is noise\n  Problem:\n\\(\\text { estimate }\\left\\{a_{i}\\right\\}_{i=1}^{L} \\text { from }\\{y[n]\\}\\)\n  Example: Predicting [[Hang Seng Index]]\n    \n      The stock market in Hong Kong\n      \n    \n  \n  Example: Real-time Predication of Flu\n    \n      Final Project on Covid data?\n      ARGO, a model combining the AR model and Google search data Yang-Santillana-Kou2015\n    \n  \n\n\nEigenvalue Problem\n\n\n  Problem: given A (nxn), find v (n) such that\n\\(\\mathbf{A} \\mathbf{v}=\\lambda \\mathbf{v}\\)\n\n\nEigendecomposition:\n\n\n  let A be symmetric\n  \n    admits a decomposition\n\n\\[\\mathbf{A}=\\mathbf{Q} \\mathbf{\\Lambda} \\mathbf{Q}^{T}\\]\n  \n  Q is orthogonal (i.e. $\\mathbf{Q}^{T} \\mathbf{Q}=\\mathbf{I}$)\n  $\\boldsymbol{\\Lambda}=\\operatorname{Diag}\\left(\\lambda_{1}, \\ldots, \\lambda_{n}\\right)$\n  no closed form in general, but can be numerically computed\n    \n      what does this mean?\n    \n  \n\n\nPageRank\n\n\n  Application example of Eigenvalue problem\n  PageRank used to rank the pages of Google search results\n  uses counts of links of various pages to determine pages' importance\n\n\nOne-Page Explanation of How PageRank Works\n\n\n  Model:\n\\(\\sum_{j \\in \\mathcal{L}_{i}} \\frac{v_{j}}{c_{j}}=v_{i}\\)\n  $c_j$ is the number of outgoing links from page j\n  $L_i$ is set of pages with a link to page i\n  $v_i$ is the importance score of page i\n  Bryan-Tanya2006\n  questions\n    \n      how to define it?\n      how to generate the solution (what if it doesn't exist?)\n      how to compute?\n    \n  \n\n\n[[Low-Rank Matrix Approximation]]\n\n\n  Needed when reduce noise, dimension reduction (most basic useful one)\n  Problem: Y (mxn) is very large matrixr &lt; min(m,n), find an (A,B) in (mxr)x(rxn)\n\\(\\text { such that either } \\mathbf{Y}=\\mathbf{A B} \\text { or } \\mathbf{Y} \\approx \\mathbf{A B}\\)\n  Y, large matrices tend to have noise\n  AB, factorization\n  B, latent representation learning\n    \n      what is this?\n    \n  \n  r, rank (low-rank = small as possible)\n  Formulation:\n\\(\\min _{\\mathbf{A} \\in \\mathbb{R}^{m \\times r}, \\mathbf{B} \\in \\mathbb{R}^{r \\times n}}\\|\\mathbf{Y}-\\mathbf{A B}\\|_{F}^{2}\\)\n\n\n[[Image Compression]]\n\n\n  Application of Low-rank Matrix Approximation\n  let Y (mxn)\n  store the low-rank factor pair (A,B), instead of Y\n    \n      what is the relationship between rank and matrices?\n        \n          if there is no definition of rank, there isn't any difference between vectors and matrices\n            \n              what?\n            \n          \n        \n      \n    \n  \n  memory cost\n    \n      from O(mn) to O((m+n)r)\n        \n          what is this O? It is written differently\n        \n      \n    \n  \n\n\n[[Principal Component Analysis]] (PCA)\n\n\n  Application of Low-rank Matrix Approximation\n  Problem: given {y_1, y_2, …, y_n} in (n) and k &lt; min(m,n), perform a low-dimensional representation\n\\(\\mathbf{y}_{i}=\\mathbf{Q} \\mathbf{c}_{i}+\\boldsymbol{\\mu}+\\mathbf{e}_{i}\\)\n  Q (mxk) is a basis\n    \n      what is a basis?\n    \n  \n  c_i's are coefficients\n    \n      what is a coefficient?\n    \n  \n  $\\mu$ is a base\n    \n      what is a base?\n    \n  \n  e_i's are errors\n  PCA (in reduction of a face image dataset) produces a set of singular vectors (1st-400th) where each one contains a certain average of faces\n    \n      so take the first 150 rank elements and discard the rest?\n      higher order = lower importance?\n    \n  \n\n\n[[Singular Value Decomposition]] (SVD)\n\n\n  SVD: any Y (mxn) can be decomposed into\n\\(\\mathbf{Y}=\\mathbf{U} \\boldsymbol{\\Sigma} \\mathbf{V}^{T}\\)\n  U (mxm) and V (nxn) are orthogonal\n  $\\Sigma$ (mxn) takes a diagonal form\n  SVD solves the low-rank matrix approximation problem\n\n\n[[Linear System of Equations]]\n\n\n  Problem: given A (nxn), y (n), solve:\n\\(\\mathbf{A x}=\\mathbf{y}\\)\n  what if your data (x) and label (y) have noise? How sensitive is your model?\n  Questions\n    \n      How to solve it?\n      How to solve it when n is very large?\n      How sensitive is the solution x when A and y contain errors?\n    \n  \n\n\n[[The Sparse Recovery Problem]]\n\n\n  Problem: given y (m), A (mxn), m &lt; n, find sparsest x (n) such that\n\\(\\mathbf{A x}=\\mathbf{y}\\)\n  sparsest = x should have as many zero elements as possible\n\n\nMagnetic resonance imaging (MRI)\n\n\n  Application of The Sparse Recovery Problem\n  Problem: MRI image reconstruction\n  image -&gt; frequency domain using Fourier coefficients -&gt; recovery by filling unobserved Fourier coefficients to zero Cand'es-Romberg-Tao2006\n    \n      unobserved Fourier coefficients?\n    \n  \n\n\n[[Low-Rank Matrix Completion]]\n\n\n  Application: recommender systems\n  Z be a preference matrix, where $z_{ij}$ records how user i likes movie j\n  some $z_{ij}$ are missing since no one watches all movies\n  Z is assumed to be low-tank (only a few factors affect users' preferences)\n  Goal: guess the unkown $z_{ij}$ from the known ones\n  Questions:\n    \n      what if every row is i.i.d, what is the rank?\n        \n          m, probability of 1\n        \n      \n      rows and columns are collated, hence low-rank works\n    \n  \n  the winners of 2009 Netflix Grand Prize used low-rank matrix approximation Koren-Bell-Volinsky2009\n  Formulation (oversimplified):\n\\(\\min _{\\mathbf{A} \\in \\mathbb{R}^{m \\times r}, \\mathbf{B} \\in \\mathbb{R}^{r \\times n}} \\sum_{(i, j) \\in \\Omega}\\left|z_{i j}-[\\mathbf{A B}]_{i, j}\\right|^{2}\\)\n  $\\Omega$ is an index set that indicates the known entries of Z\n  can't be solved by SVD\n  alternating LS may be used\n\n\nImage Denoising Problem\n\n\n  Application of Low-Rank Matrix Completion\n\n\n[[Nonnegative Matrix Factorization]] (NMF)\n\n\n  Goal: factors to be non-negative\n  Formulation:\n\\(\\min _{\\mathbf{A} \\in \\mathbb{R}^{m \\times r}, \\mathbf{B} \\in \\mathbb{R}^{r \\times n}}\\|\\mathbf{Y}-\\mathbf{A B}\\|_{F}^{2} \\quad \\text { s.t. } \\mathbf{A} \\geq \\mathbf{0}, \\mathbf{B} \\geq \\mathbf{0}\\)\n  able to extract meaningful features (by empirical studies)\n    \n      how? And what is an empirical study?\n    \n  \n\n\nImage Processing\n\n\n  basis elements extract facial features (e.g. eyes, nose, and lips) Lee-Seung1999\n\n\nText Mining\n\n$Y=AB$\n\n\n  A is the dictionary and B is the set of weights\n  basis elements recover different topics\n  weights assign each text to its corresponding topics\n\n\nFace Recognition\n\n\n  NMF-Extracted Features are sparse\n  every set correspond to a facial feature (e.g. nose, forehead)\n  how much weights for nose, forehead, etc.\n  NMF has most matrices 0s?\n    \n      yes!\n    \n  \n\n\nNMF vs. PCA in Face Recognition\n\n\n  NMF is sparse whereas PCA isn't, which means NMF is more effective\n    \n      NMF requires more train?"

    } ,
  
    {

      "title"    : "Linear Least Squares",
      "url"      : "/notes/Linear-Least-Squares",
      "category" : "",
      "tags"     : "slides",
      "content"  : "[[Matrix Analysis]]"

    } ,
  
    {

      "title"    : "How to Take Smart Notes: Zettelkasten-Method in Notion | Simply Explained | Easy Template",
      "url"      : "/notes/202101111812",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Zettelkasten]]\n\n\n  \n    steps of Zettelkasten\n\n    \n      Literature Notes (write in your own words)\n      Brief notes about the reference of the notes and some words about the total content\n        \n          what does this mean?\n        \n      \n      Fleeting Notes\n        \n          My thoughts about the ideas presented\n        \n      \n      Sorting the notes not-important and important notes -&gt; the important notes are the permanent notes\n    \n  \n  \n    example\n    \n      start a Literature note\n        \n          fill metadata\n          copy and paste logics and write literature notes about them\n            \n              does this mean paraphrasing?\n            \n          \n        \n      \n      include at the end a fleet note (what the idea is about)\n      if important, create a permanent note of the fleet note"

    } ,
  
    {

      "title"    : "Taxicab geometry",
      "url"      : "/notes/202101130921",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Mathematics]] [[Machine Learning]]\n\n\n  \n    Taxicab geometry (Manhattan dist.):\n\n    \n      backstory: because of the grid layout of the city Manhattan. Any path that the driver take, will take the same number of intersection and length to reach to the final destination. The red, blue, and yellow lines are the possible paths to take from a point into another. Although they are all different, they both have the same total length and number of intersection, and they all share the same shortest path to the final destination!\n    \n\n    \n  \n  \n    It is called also L1-norm and LASSO in [[Machine Learning]]"

    } ,
  
    {

      "title"    : "As an entry-level data-analyst, do you have any room to negotiate salary?",
      "url"      : "/notes/202101140846",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Career]]\n\n\n  If you have different offers, you should use it\n    \n      when you state the given offers, don't give the fixed salary, but give them a range including the benefits\n        \n          Bad: I have got an offer from company X for 97k\n          Good: I have got an offer from company X 100-110k with benefits\n          to negotiate, you can state that your company offers 60-65k with package and another company offers 70-75k, but I like your company due to the future opportunities and I fit better. If we could split the difference and bump to 67.5k, I'd really conf. joining your company\n        \n      \n      when you do the interview, you can ask to round your salary a bit more (56k-&gt;60k) and they will accept it as they won't need to go through recuritment again as it will cost more\n    \n  \n  If you don't have offers, you should do the following\n    \n      Study the market for the actual price that you should get and increase a bit toward it\n      If you can't ask for more salary, ask for (with any reasonable reason for why you want any or all of these things)\n        \n          more benefits\n          more off days\n          a better company laptop\n        \n      \n    \n  \n  If you are doing interviews with other companies\n    \n      If they offered you 56k at the end of the interview, you can state that the offer is too low for the given financial obligations. Unfortunately if we aren't able to that up to at least 60k, I am going to interview with these other companies that I am recruiting with (companies hate to wait for a respond after you interview with competitors)"

    } ,
  
    {

      "title"    : "10 Skills to Ace Your Data Engineering Interview",
      "url"      : "/notes/202101251301",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Data or Machine  Engineering]]\n\n\n  #RL: [[A proven approach to land a Data Engineering job]]\n  skills\n    \n      SQL\n        \n          given an ERD, write queries to answer analytical questions (e.g. leetcode problems)\n          Select, from, where, like, joins: #RL: [[SQL Tutorial for Beginners]]\n          Joins: left outer, right outer, inner, full outer, anti join and know when to use a specific join type\n          Window functions: #RL: [[6 Key Concepts, to Master Window Functions]]\n          Table relationships:\n            \n              one to many, many to many, one to one type table relationships\n              What is primary key, foreign key\n            \n          \n          Sub query, derived tables, CTEs\n          What is an index and why use it: #RL: [[What Does It Mean for a Column to Be Indexed]]\n        \n      \n      python\n        \n          list, set, dict, tuples\n          Class, methods, inheritance, iterators\n        \n      \n      Data structures and algorithms\n        \n          [[14 Patterns to Ace Any Coding Interview Question]]\n          Sliding window problem\n          Merge intervals problem\n          Graph BFS\n          Graph DFS\n        \n      \n      Data Modeling\n        \n          given a scenario, build a schema\n          Data Warehousing\n            \n              [[What is a data warehouse]]\n              What is Star schema, fact and dimension tables: #RL: [[Kimball’s Dimensional Data Modeling]]\n              What are slowly changing dimensions, especially SCD1, SCD2 and SCD3 types ?: #RL: [[https://www.wikiwand.com/en/Slowly_changing_dimension]]\n              Separation of compute and storage: #RL: [[BigQuery under the hood]]\n              External tables: #RL:[[Managed vs. External Tables]]\n              Data partitioning: #RL: [[Hive Partitions, Types of Hive Partitioning with Examples]]\n              Columnar storage formats, such as parquet, orc: #RL: [[Parquet]]\n              OLTP vs OLAP\n            \n          \n          OLTP:\n            \n              why use row based storage ? #RL: [[Row vs Column Oriented Databases]]\n            \n          \n        \n      \n      Data Pipelines\n        \n          design a pipeline and test it\n          Data pipeline dependencies, Idempotent, Time based split, late arriving events, backfilling: #RL: [[Functional Data Engineering — a modern paradigm for batch data processing]]\n          Basics of an orchestration tool like Airflow and DBT\n          Difference between ETL and ELT and when to use one over the other: #RL: [[ETL &amp; ELT, a comparison]]\n          CDC pattern: #RL: [[Change Data Capture Using Debezium Kafka and Pg]]\n          EL tools such as stitch, fivetran: #RL: [[Designing a \"low-effort\" ELT system, using stitch and dbt]]\n          Data Quality\n        \n      \n      Distributed system fundamentals\n        \n          Distributed data storage and processing: #RL: [[3 Key techniques, to optimize your Apache Spark code]]\n          Differences between batch and stream processing\n        \n      \n      Distributed Queue\n        \n          What is Kafka and when to use it: #RL: [[What, why, when to use Apache Kafka, with an example]]\n        \n      \n      \n        System Design"

    } ,
  
    {

      "title"    : "[D] Why you should get your PhD",
      "url"      : "/notes/202101251302",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[PhD]]\n\n\n  things that make PhD good:\n    \n      A productive relationship with your advisor/supervisor.\n      learn about interesting topics without expectation of concrete output.\n      Day to day work which matches the skill set you want to develop\n      build a project based on your own ideas\n      The expertise of the lab and your ability to collaborate, receive feedback and socialise with them\n      intern with industry\n      Publishing your work at top tier conferences and journals\n    \n  \n  tips to select the right PhD\n    \n      check if advisor's work is interesting and previous successful students worked with him\n      pressure to publish?\n      select a skill that will add additional value to your PhD after completion\n      narrow project or broader? Does advisor publish on different topics? Are they related? High or low quality work?\n      meet current lab members, know their exprtise, collabrate with them\n      internship during PhD is great\n      do lab members publish in top tier conf. regularly? What are the citations for papers?\n    \n  \n  \n    sunk cost fallacy\n\n    \n      When thinking about your existing projects and future projects, don’t be afraid to change tack if you worked hard on an idea and it just isn’t panning out\n      don’t be afraid to change supervisor and or people you collaborate with if you honestly gave it your best shot and things are not working out\n    \n  \n  you've really got to want it, and know why you're doing it."

    } ,
  
    {

      "title"    : "[D] Pytorch Performance guide",
      "url"      : "/notes/202101251303",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[PyTorch]]\n\n\n  summary\n    \n      Dataloader: Use num_workers &gt; 0 and pin_memory=True\n      For CNNs enable cuDNN autotuner: torch.backends.cudnn.benchmark=True\n      Max out batch_size on your GPU\n      Set bias=False in Conv layers if they are followed by BatchNorm (Damn, this makes perfect sense).\n      Instead of model.zero_grad() use for param in model.parameters(): param.grad = None\n      Disable debug APIs if you don't need them\n      Use DistributedDataParallel instead of DataParallel\n      Use Apex - Don't use apex, and use the native pytorch automatic mixed precision instead - Apex is still useful for data parallel training though. - Some more under the hood stuff. #RL: [[PyTorch Performance Tuning Guide - Szymon Migacz, NVIDIA]] PYTORCH PERFORMANCE\nTUNING GUIDE\n      PyTorch Lightning"

    } ,
  
    {

      "title"    : "[D] Is there a theoretically justified reason for choosing an optimizer for training neural networks yet in 2020?",
      "url"      : "/notes/202101251304",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Machine Learning]]\n\n\n  optimization isn't used in practice, just basics are used: #RL: [[Overview of mini-batch gradient descent]], and ADAM is abused\n  theoretical implementation is hard compared to practice\n    \n      pragmatic thought\n      A big issue is that very few people are actually interested in developing new theories in this field. Everyone is too focused on chasing benchmarks, on being \"pragmatic\" and on hyping up models that rely primarily on scale to succeed (eg GPT-3).\n    \n  \n  classical optimization methods are designed to solve very different problems.\n    \n      NNs don't need superlinear convergence. Convergence rate is a very important property in optimization theory. You can get thousands, even millions of accurate digits in just a handful of iterations. But that doesn't matter for training NNs.\n    \n  \n  Forget theoretical justification, even empirical concerns seem to be ignored when people choose optimizers.\n    \n      #RL: [[Decoupled Weight Decay Regularization]], [[New State of the Art AI Optimizer: Rectified Adam (RAdam). Improve your AI accuracy instantly versus Adam, and why it works.]], [[Lookahead Optimizer: k steps forward, 1 step back]], and [[Stochastic Gradient Methods with Layer-wise Adaptive Moments for Training of Deep Networks]]\n      comparison: #RL: [[Descending through a Crowded Valley – Benchmarking Deep Learning Optimizers]]\n    \n  \n  There's literally no theory that can justify the ridiculous performance of NNs.\n    \n      In almost all other statistical domains increasing the size of the parameter space requires a quadratic increase in samples. Meanwhile Deep learning does almost the opposite. DL is stupidly effective and if we can't even understand why the solutions to these problems are so strong there's no way we can come up with a theory based method to do better.\n    \n  \n  It really just comes down to the fact that a simple optimizer like ADAM has been shown to sufficiently well at optimizing many different types of NN models across a broad range of tasks. On top of that, as a first order method parameter updates with ADAM are extremely cheap to compute compared to higher order optimization techniques. So even though you could use more complex, higher order techniques (and plenty of papers over the years have explored alternatives), ADAM trains faster and achieves nearly as good final model performance as anything else. Theory doesn't really matter for much when in practice a simpler technique performs basically as well."

    } ,
  
    {

      "title"    : "A practical guide for better-looking python code",
      "url"      : "/notes/202101251520",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Software Engineering]]\n\n\n  #RL: [[Nine simple steps for better-looking python code]] and [[Ten Essays on Fizz Buzz]]\n\n\n\n  Do not push to the master branch\n    \n      Rules for branches\n        \n          Require pull request reviews before merging\n          Require status checks to pass before merging (setting up CI/CD)\n          Include administrators\n        \n      \n    \n  \n  Continuous Integration / Continuous Delivery\n  FizzBuzz\n  Pre-commit hook"

    } ,
  
    {

      "title"    : "Billionaires Build",
      "url"      : "/notes/202101251521",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Career]] [[Startup]]\n\nHow to be a successful YC founder:\n\n\n  whether what you're making will ever be something a lot of people want\\\n  You build something to serve one location, and then expand to others.\n    \n      There have to be some people who want what you're building right now, and want it so urgently that they're willing to use it, bugs and all, even though you're a small company they've never heard of.\n      Who are your first users going to be, and how do you know they want this? If I had to decide whether to fund startups based on a single question, it would be \"How do you know people want this?\"\n      The best thing you can do in a YC interview is to teach the partners about your users. So if you want to prepare for your interview, one of the best ways to do it is to go talk to your users and find out exactly what they're thinking. Which is what you should be doing anyway.\n    \n  \n  Competitors are rarely what kills startups. Poor execution does.\n  The partners don't expect your idea to be perfect\n  in most ambitious undertakings: to be genuinely interested in what you're building. This is what really drives billionaires, or at least the ones who become billionaires from starting companies. The company is their project.\n  One thing few people realize about billionaires is that all of them could have stopped sooner. They could have gotten acquired, or found someone else to run the company. Many founders do. The ones who become really rich are the ones who keep working."

    } ,
  
    {

      "title"    : "How I use Anki as an A-level Student",
      "url"      : "/notes/202101251523",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Anki]]\n\n\n  don't start big, 75-100 is good. If you want to start be, do 250 a day\n  yse tags instead of subdecks\n  use Cloze\n    \n      #Q: what are those?\n    \n  \n  study by card state or tag\n    \n      all review cards in random order\n      all cards in random order (don't reschedule)"

    } ,
  
    {

      "title"    : "How to learn pure mathematics on your own: a complete self-study guide",
      "url"      : "/notes/202101251524",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Mathematics]]\n\n\n  Real Analysis\n    \n      short paper, http://assets.press.princeton.edu/chapters/s10825.pdf\n      Understanding Analysis, book\n      lectures: https://www.youtube.com/channel/UCLzpR8AiHx9h_-yt2fAxd_A/playlists\n    \n  \n  Linear Algebra\n    \n      Linear Algebra Done Right, book\n      lectures: https://www.youtube.com/playlist?list=PLGAnmvB9m7zOBVCZBUUmSinFV0wEir2Vw\n      easier problems, use this book: “Linear Algebra” by Insel, Freidberg, and Spence\n    \n  \n  Topology\n    \n      book: “Topology through Inquiry” by Su and Starbird (missing)\n      course page: http://danaernst.com/teaching/mat441s19/materials/\n      free notes: http://www.math.toronto.edu/ivan/mat327/?resources\n      Point Set Topology Playlist: https://www.youtube.com/playlist?list=PLbMVogVj5nJRR7zYZifYopb52zjoScx1d\n      Algebraic Topology Playlist: https://www.youtube.com/playlist?list=PL41FDABC6AA085E78\n    \n  \n  Differential Equations\n    \n      book: “Differential Equations with Boundary Value Problems” by Zill and Cullen\n        \n          Chapter 1 (Introduction!)\n          Chapter 4.1 (Preliminary Theory of Linear Equations)\n          Chapter 4.3 (Homogeneous Linear Equations with Constant Coefficients)\n          Chapter 7 (Laplace Transform)\n          Chapter 8 (Systems of Linear Differential Equations)\n          Chapter 9 (Numerical Methods)\n          Chapters 11, 12, 13 (Fourier Series and Partial Differential Equations)\n        \n      \n    \n  \n  Complex Analysis\n    \n      book: “Visual Complex Analysis” by Tristan Needham\n      Wesleyan University Playlist: https://www.youtube.com/watch?v=CVpMpZpd-5s&amp;list=PLi7yHjesblV0sSfZzWdSUXGO683n_nJdQ&amp;ab_channel=PetraBonfert-Taylor\n      best book for beginners: A Friendly Approach to Complex Analysis\n    \n  \n  Abstract Algebra\n    \n      book: Contemporary Abstract Algebra\n      Socratica Abstract Algebra Playlist: https://www.youtube.com/playlist?list=PLi01XoE8jYoi3SgnnGorR_XOW3IcK-TP6\n      depth videos\n        \n          Group Theory: https://www.youtube.com/playlist?list=PLEAYkSg4uSQ1Yhxu2U-BxtRjZElrfVVcO\n          Ring and Field Theory: https://www.youtube.com/playlist?list=PLEAYkSg4uSQ3AaON5oCbS6ecwKsoopBN3\n        \n      \n    \n  \n  Differential Geometry\n    \n      book for intuition: “A Geometric Approach to Differential Forms” by David Bachman\n      book for rigor: “Introduction to Manifolds” by Loring Tu\n      WhyBMaths: https://www.youtube.com/watch?v=RW5lJiKZHd8&amp;list=PLxBAVPVHJPcrNrcEBKbqC_ykiVqfxZgNl&amp;ab_channel=WHYBmaths"

    } ,
  
    {

      "title"    : "How to Make Your Code Reviewer Fall in Love with You",
      "url"      : "/notes/202101251525",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Software Engineering]]\n\n\n  Review your own code first\n    \n      use diff view\n    \n  \n  Write a clear changelist description\n    \n      Everything you just told me should be on the first page of your design doc\n      I wrote the design document imagining how my teammates would read it, but I failed to consider other readers\n      Your changelist description should summarize any background knowledge the reader needs\n      A good changelist description explains what the change achieves, at a high level, and why you’re making this change.\n      #RL: [[How to Write a Git Commit Message]] and [[My favourite Git commit]]\n    \n  \n  Automate the easy stuff\n    \n      use CI\n      use pre-commit hooks\n    \n  \n  Answer questions with the code itself\n    \n      You need to explain it to everyone\n      The best way to answer someone’s question is to refactor the code and eliminate the confusion.\n      Can you rename things or restructure logic to make it more clear? Code comments are an acceptable solution, but they’re strictly inferior to code that documents itself naturally.\n    \n  \n  Narrowly scope changes\n    \n      Scope creep is a common anti-pattern in code reviews\n      do one thing\n      #RL: [[Curly's Law: Do One Thing]]\n    \n  \n  Separate functional and non-functional changes\n    \n      The developer either fails to recognize what they did or decides that the new formatting is better. They send out a two-line functional change buried in hundreds of lines of non-functional whitespace changes.\n      Developers also tend to mix changes inappropriately while refactoring. I love it when my teammates refactor code, but I hate it when they refactor while changing the code’s behavior.\n      If a piece of code requires refactoring and behavioral changes, it should happen in two to three changelists:\n        \n          Add tests to exercise the existing behavior (if they’re not already there).\n          Refactor the production code while holding the test code constant.\n          Change behavior in the production code and update the tests to match.\n        \n      \n      By leaving the automated tests untouched in step 2, you prove to your reviewer that your refactoring preserves behavior.\n      When you reach step 3, your reviewer doesn’t have to untangle the behavioral changes from the refactoring changes, as you’ve decoupled them ahead of time.\n    \n  \n  Break up large changelists\n    \n      A changelist’s complexity grows exponentially with the number of code lines it touches. When my changes exceed 400 lines of production code, I look for opportunities to break it up before requesting a review.\n    \n  \n  Respond graciously to critiques\n    \n      #RL: [[How to Do Code Reviews Like a Human (Part One)]] and [[The Seven Habits of Highly Effective People by Stephen R. Covey]]\n    \n  \n  Be patient when your reviewer is wrong\n    \n      #RL: [[Two Ways To Design]]\n      refactor the code, or add comments that make the code more obviously correct\n      If the confusion stems from obscure language features, rewrite your code using mechanisms that are intelligible to non-experts.\n    \n  \n  Communicate your responses explicitly\n  Artfully solicit missing information\n    \n      Whenever a reviewer gives me unclear feedback, I always respond with some variation of, “What would be helpful?”\n    \n  \n  Award all ties to your reviewer\n    \n      When your reviewer makes a suggestion, and you each have roughly equal evidence to support your position, defer to your reviewer. Between the two of you, they have a better perspective on what it’s like to read this code fresh.\n    \n  \n  Minimize lag between rounds of review\n    \n      Once you send your code out, driving the review to completion should be your highest priority."

    } ,
  
    {

      "title"    : "Linking Your Thinking",
      "url"      : "/notes/202101251526",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Obsidian]]\n\n\n  \n    Obsidian for Beginners\n\n    \n      hotkeys:\n        \n          ctrl+e = toggle edit mode\n          ctrl+o = open Quick Switcher\n          ctrl+shift+f = search in files\n          ctrl+alt+ARROW = go back/forward\n        \n      \n      #IQ: \"make notes, don't take notes\" - Nick Milo\n    \n  \n  \n    LYT Originals\n\n    \n      \n        https://www.youtube.com/watch?v=KFU72m_7-Oo&amp;list=PL3NaIVgSlAVKWUrFOkDW7AEjXaiPQu_IM&amp;index=9\n\n        \n          \n            setup\n\n            \n              00 Home\n                \n                  top\n                    \n                      title\n                      description\n                      header photo\n                      line\n                    \n                  \n                  content\n                    \n                      index\n                        \n                          research\n                            \n                              01 interesets #MOC #evergreen\n                              02 Concepts #Concept #Develop\n                            \n                          \n                          Inputs\n                            \n                              03 Sources #Source #Commentary\n                              04 Reference #Person #Ref\n                              05 Education #Class #Homework #Tutorial\n                            \n                          \n                          Outputs\n                            \n                              06 Writing #Writing #Writing-idea\n                              07 Documentation #Cribsheet #Documentation #Process\n                              08 Journal #Log\n                            \n                          \n                          Projects\n                            \n                              09 Compass\n                              10 Personal #Conversation #Context\n                            \n                          \n                        \n                      \n                    \n                  \n                \n              \n              01 Interests\n                \n                  Computer and Technology\n                    \n                      description\n                      Computer History MOC\n                        \n                          description\n                        \n                      \n                      Computer Futurism MOC\n                        \n                          description\n                        \n                      \n                      etc.\n                    \n                  \n                  Systems and Tools\n                    \n                      description\n                      Tools for Thought MOC\n                        \n                          description\n                        \n                      \n                      \n                        etc.\n                      \n                    \n                  \n                \n              \n              03 Sources\n              same top\n              Tag Index\n                \n                  Source Processing\n                    \n                      description\n                      #Source #Commentary\n                    \n                  \n                  Source Type\n                    \n                      description\n                      #Notification #Fiction #Article #Book #Podcast #Video #Lecture #Film\n                    \n                  \n                  Reading Status\n                    \n                      description\n                      #To-Read #Reading #Finished #To-Process #Not-Finished\n                    \n                  \n                  Naming Conventions\n                    \n                      description\n                        \n                          Author First + Last Name - Name of Article (YYYY)\n                        \n                      \n                      Barrier to Entry\n                    \n                  \n                \n              \n            \n          \n          \n            Header embedding\n            \n              embed a section of a note that isn't mature yet\n            \n          \n        \n      \n    \n  \n  \n    LYT Q&amp;As\n\n    \n      tags = weak links\n        \n          #develop = still in progress\n        \n      \n      LYT add to Zettlekasten\n        \n          LYT = fluid framework to manage and structure notes (middle-up and middle-bottom)\n          Zettlekasten = note structure (bottom-up)\n          folders (top-down)\n        \n      \n      new notes that doesn't belong to MOCs yet, link to concepts MOC so you can view them on the links to be added to MOCs later on\n      use #Evergreen to refactor a note\n      doesn't add MOCs to the home note\n        \n          just keep the following\n            \n              mindsets MOC\n              concepts MOC\n              interests MOC\n              Writing MOC\n              Sources MOC\n              People MOC\n              Health MOC\n              Goals MOC\n              PKM MOC\n              Compass MOC\n              Lists MOC\n              Projects MOC\n            \n          \n          setup\n            \n              notes\n              zettlekasten which links local notes\n              pull zettlekasten to MOC\n              MOC maps to each others\n              home note\n            \n          \n        \n      \n      using tags to move around\n        \n          000 Home\n            \n              0X0 YYY MOC (always case for MOC file)\n                \n                  add to the top, links: 000 Home\n                \n              \n              note level\n                \n                  add to the bottom, links: 0X0 YYY MOC\n                \n              \n            \n          \n        \n      \n      Progressive Summerization = the idea of highlighting what you read and summarize it into a note (aka copy-paste)\n        \n          it should be exteremly low as you aren't making notes, but taking them\n        \n      \n      notes should be about a page long\n      create notes based on the idea of the article not the article\n      \n        when doing a research about a project and would like to use MOC\n\n        Title\n\n        Topic 1 MOC\n\n        link\nlink\nlink\n\n        Topic 2 MOC\n\n        link\nlink\nlink\n\n        Topic 3 MOC\n\n        link\nlink\nlink\n      \n      use Inbox folder to create new notes from resources or quick notes that doesn't have a base\n        \n          then every week, try to refactor the note and add it to a special MOC to be an atomic note by itself\n        \n      \n      Using Zettlekasten system when writing notes for:\n        \n          meetings\n          personal tracking\n          trackingll\n          logging\n        \n      \n      MOC system\n        \n          Inner-led Sense-making\n            \n              Mindsets\n              Concepts\n              Interests\n              Writings\n            \n          \n          Outer-led Sense-making\n            \n              Sources\n              People\n            \n          \n          Personal Management\n            \n              Health\n              Goals\n              Compass\n            \n          \n          Knowledge Management\n            \n              PKM\n              Lists?\n            \n          \n          Projects\n            \n              Projects\n            \n          \n        \n      \n      access note again, use a #tag\n      Using folders for publishing\n        \n          public\n          private\n          etc.\n        \n      \n      TOC vs. MOC\n        \n          TOC is a finalized for publication\n          \n            MOC is more fluid"

    } ,
  
    {

      "title"    : "Mutlitasking As A Graduate Student",
      "url"      : "/notes/202101251527",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Productivity]]\n\n\n  work in parallel by working on multiple projects at the same time\n  how? manage allocation of time needed to work on those projects/tasks\n  this will help your mind to successful accomplish multiple projects/tasks while being on track\n  [[Procrastination But Mitigated]] shows a method of managing those multiple projects\n  \n    best approach might be to work allocate a solid unchanged timeframe for the most important thing, such as thesis work, and have multiple projects, such as homework, articles, etc. with different completion time and timeframe to be worked on in parallel.\n  \n  I think the time when to work is important. Working early in the morning will result to a more clear mindset, hence, high quality work to be done\n  try to work on the most important things early on the morning for clearlity sake"

    } ,
  
    {

      "title"    : "Procrastination But Mitigated",
      "url"      : "/notes/202101251528",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Productivity]]\n\n\n  Multiple tasks handling\n  given example\n    \n      3 tasks to be completed in a week\n      their priorities: 6,4,2\n      expected of completion hours: 10, 8, 6\n      allocated time for daily work: 10/6, 8/4, 6/2\n      so I will be working on\n        \n          1: 1:45h\n          2: 2h\n          3: 3h"

    } ,
  
    {

      "title"    : "Skinny Pandas Riding on a Rocket (PyDataGlobal 2020)",
      "url"      : "/notes/202101251529",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Pandas]]\n\ndf_few_cols = df[['country', 'pt', 'date', 'price']]\ndf_few_cols.info() # doesn't show the true memory, 777.2+MB\ndf_few.cols.info(memory_usage=\"deep\") # show true memory, 3.4GB\n\n# slimmer\ndf_slimmer_cols = pd.DataFrame({ 'country_cat': df_few_cols.country.astype('category'),\n'pt_cat': df_few_cols.pt.astype('category'),\n'date_cat': df_few_cols.date.astype('category'),\n'price_i32': df_few_cols.price.astype('int32')\n})\n\n%time df_few_cols.pt.value_countr() # 1.96s\n%time df_slimmer_cols.pt.value_countr() # 146ms\n\n\n\n  memory_profiler = profile RAM usage in python\n    \n      mprof = track whole-program execution\n      %memit = track cost of single command"

    } ,
  
    {

      "title"    : "What is the best performance fix you ever achieved by changing only a few lines of code?",
      "url"      : "/notes/202101251530",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[pandas]] [[Data Science]]\n\n\n  This is more of a general rule: if you're using for loops in combination with Pandas, there's likely a way in pure Pandas for a performance improvement. Usually it's the first thing I go through when refactoring code.\n    \n      Pandas and numpy has a lot of built-in functions that are compiled (and sometimes use SIMD etc. under the hood).\n      if you're implementing an algorithm or doing something complicated, it actually makes sense to keep it simple using loops and built-in python stuff and compiling it instead of trying to use numpy/pandas.\n      The reason is simple: compilers are better at optimizing code than you are.\n      The JIT compiler handles it.\n    \n  \n  if you are using SQL learn indexes, if you're using HDFS learn partitions\n  from ~2 min per run to ~8 seconds by, at various points in time:\n    \n      swapping out indexing a pandas dataframe (which is suprisingly slow) to indexing a list of dict [code-0]\n      wrapping a cache decorator around some hot functions that get called redundantly\n      thowing some numba jit decorators around some hot matrix operations\n      A weird one was telling numpy to stop using so many threads, which was actually slowing down the code due to the overhead of the threads\n      building pandas masks up incrementally rather than doing it in the inner loop\n      a whole bunch of small, but effective optimizations that can be summarised as \"stop doing the same thing every time inside a for loop, instead, do it before the for loop\" - this was sometimes obsfucated by function calls\n      some cases of \"track and save the data now when it is cheap rather than recalculating it later on\"\n      #RL: [[Profiling Python using cProfile: a concrete case]]\n    \n  \n  comparing two different types, make both of them the same\n  Using Python’s set instead of a list for common if var in container checks. Really makes a difference if you have a bunch of items!\n  CPU to GPU with RAPIDS\n    \n      Pandas - &gt; cudf\n      numpy -&gt; cupy\n      networkx -&gt; cugraph\n    \n  \n\n\n[code-0]\n\n\t# before, surprisingly slow\n\tdf = pd.DataFrame.from_dict([{\"a\": 1, \"b\": 2}, {\"a\": 3, \"b\": 4}])\n\tfor idx in range(len(df)):\n\t\tdatum = df.iloc[idx]\n\t\t# do stuff\n\t# after, noticeably faster\n\tdata = [{\"a\": 1, \"b\": 2}, {\"a\": 3, \"b\": 4}]\n\tfor idx in range(len(df)):\n\t\tdatum = datum[idx]\n\t\t# do stuff\n\t# enumerate is faster\n\tfor idx, datum in enumerate(data):\n\t\t# do stuff"

    } ,
  
    {

      "title"    : "When attending lectures, what is your notetaking process?",
      "url"      : "/notes/202101251531",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Studying]] [[Anki]]\n\n\n  Air-tun-91\n    \n      method\n        \n          before lecture\n            \n              skim assigned chapter\n              read through chapter backwards\n                \n                  e.g. take learning objective 1 and find the answer\n                  take notes of the ideas\n                  solve simple problems\n                  make an anki card of it\n                \n              \n            \n          \n          during lecture\n            \n              take notes in Q+A form\n                \n                  e.g. what is another name for the ….? ANS: …\n                \n              \n            \n          \n          after lecture\n            \n              skim notes\n              make the Q+A into Anki cards\n            \n          \n        \n      \n      The lecture is supposed to reinforce the reading you already did, and walk you through the most important concepts\n      You should not start putting information into your spaced repetition system before you understand it\n      You cannot actively listen to a lecture, process the material, understand it instantly, and make a flashcard while continue to actively listen\n    \n  \n  nofunatall_17\n    \n      method\n        \n          before lecture\n            \n              make an outline of the lecture in my own words\n              highlight key words or topics\n              write a few questions on what I think the important topics are\n            \n          \n          during\n            \n              take some notes\n              try to get an idea of main ideas and connect them\n            \n          \n          1st pass\n            \n              color code info highlights and underlines\n              fill in missing info\n            \n          \n          2nd pass\n            \n              have notes open and make anki cards from them\n              double check with premade decks on the big topics covered too\n            \n          \n          after/during review\n            \n              if there is a difficult concept to make a card for, don't understand fully, or miss it a lot on Anki, I will read up or search for more info about it\n              make a review sheet for it\n              take a screenshot of it and add it to revalvent cards"

    } ,
  
    {

      "title"    : "Why Obsidian Will Overtake Roam",
      "url"      : "/notes/202101251532",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Obsidian]]\n\n\n  What is your PKM Personality?\n    \n      Collector = Love ideas\n      Databaser = Love storing ideas\n      Writer = Love building stories\n      Connector = Love relating ideas\n    \n  \n  Obisdian\n    \n      Databasing = linking everything\n        \n          building around the idea\n        \n      \n      Writing mainly\n        \n          active thinking about ideas\n        \n      \n      Connecting ideas\n      #IQ: \"When we read, another person thinks for us: we merely repeat his mental process… This is the case with many learned persons: they have read themselves stupid.\" - Arthur Schopenhauer\n    \n  \n  Why Obsidian is better than Roam\n    \n      local files: offline, no database\n      file-based: every file in its own\n      plain text: markdown\n      no lock-in: you can export and play around with\n      free"

    } ,
  
    {

      "title"    : "Writing a technical book: from idea to print",
      "url"      : "/notes/202101251533",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Writing]]\n\n\n  readers who knew the pattern beforehand wanted a technical manual, while conference attendees (who were being introduced to the pattern for the first time) wanted to know why the pattern matters.\n  come up with ideas\n    \n      outline ideas\n      separate based on chapters\n    \n  \n  writing process\n    \n      Research &amp; write code\n      Write the chapter while referencing the code\n      Revise, more research, edit code\n    \n  \n  writing style\n    \n      Problem: describes the ML challenge a pattern addresses\n      Solution: describes one approach to solving the problem, including code snippets and recommended tooling for solving the problem\n      Tradeoffs and Alternatives: extended discussion on the pattern, including tools not covered in the Solution section, potential gotchas, and related solutions\n    \n  \n  review process\n    \n      authors review together, each others' work\n      send to selected expert readers in the domain for feedback\n      send to publisher\n    \n  \n  burden? Ask for help to complete this with ease"

    } ,
  
    {

      "title"    : "Niklas Luhmann",
      "url"      : "/notes/Niklas-Luhmann",
      "category" : "",
      "tags"     : "people",
      "content"  : "[[060 People]]"

    } ,
  
    {

      "title"    : "Understanding Region of Interest — (RoI Pooling)",
      "url"      : "/notes/202102272146",
      "category" : "",
      "tags"     : "literature",
      "content"  : "[[Computer Vision]]\n\n\n  Region of Interest (RoI) = proposal network\n  RoI are mapped to the model's feature map\n  Quantization of coordinates on the feature map\n    \n      Quantization = from real numbers to discrete numbers\n      In case of feature maps, flooring values\n    \n  \n  RoI Pooling\n    \n      RoI Pooling layer -&gt; FCL (with fixed size)\n      4x6 (RoI) -&gt; 3x3 (RoI pooling)\n      Pooling could be Max or Avg.\n    \n  \n\n\nRoI generates proposals for the model to use in later steps. The process of RoI contains the following: \n1) Selection of"

    } 
  
]