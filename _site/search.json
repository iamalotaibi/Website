[
  
    {

      "title"    : "How I managed my time effectively",
      "url"      : "/posts/test",
      "content"  : "Rules\n\nI try to follow these rules:\n\nTime-blocks\n\n\n  Session (50/10): I typically work/study for 50 minutes where I work on one thing for the entire time. There isn't anything important in life besides this one thing. If life interrupt me, I will try to stop the interuption and try to get back to my zone at soon as possible. After the completion of the 50 minutes, I will take a break for 10 minutes where I will be standing and walking the majority of the time. I usually do life tasks (e.g. washing dishes, making coffee, throw trashes, etc.) then I will check my phone for messages real quick without checking any of my socials.\n  Block (6/1): Every block has 6 sessions and 1 long break. For the sessions, I can have combine two sessions if I am excited in continue what I work on and I feel that I am close by of completion and I know for sure that I have some gas to continue the same quality of work if I took break.\n\n\nTypical day\n\n\n  5:00-6:00am: Morning Routine\n  6:00-12:00pm: Deep Work 1\n  12:00-1:00pm: Lunch (break)\n  1:00-7:00pm: Deep Work 2\n  7:00-9:00pm: Night Routine"

    },
  
  
    {

      "title"    : "Discriminative Appearance Modeling with Multi-track Pooling for Real-time Multi-object Tracking",
      "url"      : "/publications/gabor",
      "content"  : "Abstract"

    },
  
  
    {

      "title"    : "Exploring Robot",
      "url"      : "/projects/exploring-robot",
      "content"  : "Instructions\n\n\n  Code A*\n  Download world.csvPreview the document\n  Write a program to create a 4-connected graph and run an A* search from vertex (0,0) to vertex (19,19) across the obstacle map provided in world.csv.\n  The world is a 20×20 grid of cells\n  The world.csv file is an occupancy grid map: 1 means the grid cell is occupied and you can’t move through it\n  Edge costs are 1\n  Your code should output the final path (either plot it or print out the vertex coordinates) and associated path cost.\n  Comment your code to demonstrate that you understand the algorithm.\n  What to turn in:\n    \n      A zip file of your commented A* code including world.csv.\n      A cover sheet (PDF) listing:\n      Web sites you used\n      People you worked with\n      The final path\n      Your heuristic function (in English)\n      How you implemented the graph and priority queue\n      Any known bugs/issues\n    \n  \n\n\nA few notes:\n\n\n  4-connected means that you can travel from a cell to any of the cardinal neighbors (north, south, east, west).\n  Broadly speaking, there are two ways you can represent the graph\n  As an adjacency matrix with a function that returns valid neighbors for a given vertex when queried, or\n  As a list of vertices and a list of edges.\n  You need to demonstrate that you understand how the algorithm works and the best way to do this is to comment relevant lines of code. Marks will be awarded accordingly.\n  There are plenty of resources are available to you online, you may take inspiration from existing implementations that you find, but see Note 3 above.\n\n\nRubric and Grade\n\n\n  \n    \n      Criteria\n      Ratings\n       \n      Pts\n    \n  \n  \n    \n      Sends waypoints to the robot\n      3.0 pts   Full Marks\n      0.0  pts  No Marks\n      3.0\n    \n    \n      Uses SLAM to create a map\n      3.0  pts  Full Marks\n      0.0   pts   No Marks\n      3.0\n    \n    \n      Has a documented exploration strategy\n      7.0    pts    Full Marks\n      0.0   pts   No Marks\n      7.0\n    \n    \n      Strategy works in all world files (entire space visited)\n      7.0    pts    Full Marks\n      0.0   pts   No Marks\n      7.0\n    \n    \n      Mechanism for detecting unexplored area\n      5.0  pts  Full Marks\n      0.0   pts   No Marks\n      5.0\n    \n    \n      Mechanism for detecting when exploration strategy fails  Failure case: didn't get to way point, what do you do next?\n      7.0   pts   Full Marks\n      0.0   pts   No Marks\n      7.0\n    \n    \n      Algorithm/strategy for getting to unexplored area\n      3.0   pts   Full Marks\n      0.0   pts   No Marks\n      3.0\n    \n    \n      Behaves \"reasonably\" on other test worlds  Doesn't crash, makes some attempt to navigate to unexplored areas\n      5.0  pts  Full Marks\n      0.0   pts   No Marks\n      5.0\n    \n    \n      Total Points:\n       \n       \n      40.0\n    \n  \n\n\n\n\nReport\n\nDiscussion of the exploration problem\n\nIn this problem we are designing an exploration package utilizing the gmapping and nav_bundle packages to allow a simulated robot to explore an unknown environment. Our algorithm will have to set waypoints to move our robot towards the unexplored areas while avoiding obstacles. The robot should be reasonably robust to noisy odometry and mapping data, and it should be able to recognize when waypoints cannot be reached.\n\nDiscussion of your gmapping and nav_bundle package implementations\n\nFrom the gmapping bundle we are only using the occupancy grid. This grid is used to find \"frontier\" points (points between explored and unexplored areas). We are also reading the map meta data which gives us the resolution of the occupancy grid in meters/pixel. This gives us the ability to transform the occupancy grid data into Cartesian coordinates. The map is also saved when a waypoint is generated and used to verify that the robot is staying in known areas only, ensuring that the robot doesn't run into walls even if it didn't know about them before it calculated it's path.\n\nFrom the nav_bundle package, we are using the waypoint commands: twist, base_link_goal, path_reset, move_base_cancel, and ready_pub.  Clear and cancel are used to have the robot only pursue a single waypoint at a time.  Waypoints generated using the occupancy grid which are then translated and rotated into the robot's local coordinate system then set as a waypoint using Twist.\n\nDiscussion of your waypoint allocation algorithm\n\nWaypoints are generated procedurally using an 61x61 filter that scans the frontier points on the occupancy grid. The robot's exploration policy defines frontier points as being known unoccupied locations where the robot would end near unknown locations. This filter only selects points that are centered on an explored point, have no obstacles within a specified distance from the center, have a threshold percentage of unexplored cells, and aren't where the robot has been before. These cells are then weighted by the percentage of unknown cells and euclidean distance from the robot. It then uses an A* algorithm to determine if there is a known path from the current location to the candidate location. Validating the path allows the robot to exclude candidate points that would be outside of the map or within obstacles.\n\nIf the robot enters a region that was unexplored when the waypoint was created, it will clear the waypoint queue, cancel the current waypoint, turn 360 degrees, back up 1.5m, and generate a new waypoint. With the current implementation of the nav_bundle, the robot can select paths that pass through unknown locations. If the robot then passes though the unknown location and discovers that there is a wall blocking the path, the robot will not reroute in order to find the proper path. Instead, the robot will simply crash into the wall. To prevent incorrect path planning through unknown locations, we save how the map looked when the nav_bundle chose that path, and tell the robot to stop and reroute if we reach a location that was previously unknown, making our robot's path robust to new information.\n\n\n    \n\\begin{algorithm}\n\\caption{FindNextWaypoint}\n\\begin{algorithmic}\n\\Procedure{FindNextWaypoint}{$map$, $window\\_size$, $stride\\_length$, $visited\\_locations$, $robot\\_loc$, $avoidance\\_radius$, $empty\\_radius$, $RESOLUTION$}\n\n\\State $potential\\_candidates \\gets \\text{[]}$\n\n\\For{\\textbf{every} $center\\_cell \\textbf{ in } map \\textbf{ that is greater than } stride\\_length$ \\textbf{apart from each other}}\n    % if the center and the surrounding cells are not empty:\n    %   continue\n    \\State $skip \\gets false$\n    \\For{\\textbf{every} $neighbor\\_cell$\\textbf{ in a }$avoidance\\_radius$\\textbf{ away from }$center\\_cell$}\n        \\If {alreadyVisited($visited\\_location$, $neighbor\\_cell$)}\n            \\State $skip \\gets true$\n            \\State \\textbf{break}\n        \\EndIf\n    \\EndFor\n    \\If {$skip == true$}\n        \\State \\textbf{continue}\n    \\EndIf\n    \\For{\\textbf{every} $neighbor\\_cell$\\textbf{ in a }$empty\\_radius$\\textbf{ away from }$center\\_cell$}\n        \\If {getMapValue($visited\\_location$) $\\neq$ $0$}\n            \\State $skip \\gets true$\n            \\State \\textbf{break}\n        \\EndIf\n    \\EndFor\n    \\If {$skip == true$}\n        \\State \\textbf{continue}\n    \\EndIf\n    \n    \\State $cell\\_sum \\gets \\text{sum(all cells within } window\\_size/2 \\text{ from } center\\_cell \\text{)}$\n\t\n\t\\State $potential\\_candidates\\text{.append(}center\\_cell\\text{)}$\n\\EndFor\n\n\\State $candidate \\gets \\text{sorted(}potential\\_candidates\\text{)} $\n\\State $candidate \\gets  potential\\_candidates\\text{.pop()} $\n\\While{$\\textbf{not } \\text{reachableByAStar(} robot\\_loc, candidate\\text{)}$}\n    \\State $candidate \\gets  potential\\_candidates\\text{.pop()} $\n    \\State $best\\_loc=candidate$\n\\EndWhile\n\n\\State $candidate  \\gets \\text{convert\\_row\\_col\\_to\\_coord}best\\_loc, RESOLUTION, map\\text{)} $\n\n\\State \\textbf{return} $candidate$\n\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n\n\n\n\n\n\n\n  Inputs:\n    \n      map: The current occupancy grid\n      window_size: Width of the sliding window used to generate candidate points\n      stride_length: Row much to shift the sliding window with each iteration\n      visited_locations: Grid with same size as map representing the locations we have been to\n      robot_loc: Currently location of the robot\n      avoidance_radius: Radius around candidate waypoint that should not contain walls\n      empty_radius: Radius around candidate waypoint that should be empty\n      RESOLUTION: How many meters per cell\n    \n  \n  Outputs:\n    \n      candidate: The best potential waypoint to go to next\n    \n  \n\n\nAnalysis of your algorithm’s exploration performance\n\nThe algorithm has managed full coverage in all provided maps. This algorithm is far from perfect, periodically getting stuck (although it is able to correct itself), and periodically choosing waypoints outside of the map. The algorithm can struggle to come up with waypoints in a reasonable amount of time (typically 20 seconds) due to the need to run A* after a potential candidate is selected.\n\nThe algorithm tended to get the robot stuck in one area, ensuring that every cell in the immediate area. This behavior causes the exploration process to take a long time in the maze map if it selects a point on the other side of a wall potentially causing long travel times.\n\nDid it result in full coverage of the environment (provide a screenshot from rviz)?\n\n\n    \n    \n    \n\n\n\tFigure 1: Random Dots Map, The Office Map, and The Maze Map\n\n\nThis algorithm resulted in full exploration of the robot's environment with a reasonable success rate. The many dots map was the first map that the robot completed, it completed the map in around 20 minutes. Euclidean distance in this map is an accurate way to approximate path distance since the map isn't divided into rooms, making it an ideal scenario for this algorithm. The office map saw completion times of around 22 minutes. This was largely due to the euclidean distance heuristic that had the robot fully explore each room before moving on. This algorithm struggled with the maze file since it had a habit of setting waypoint on the other side of a wall making it drive back and forth around the entire map, making little but steady progress.\n\nProvide suggestions on how your waypoint allocation algorithm could be improved.\n\nThe algorithm should use an A* search in order to find the nearest waypoints instead of using euclidean distance. This should make the exploration time faster since it would travel through fully explored areas less often in order to reach new locations. Computationally expensive functions (such as A*) could be rewritten in C++ in order to cut down on computational cost. The robot's policy for getting unstuck could also be improved. Currently we assume that the robot gets stuck, it is facing a wall and can therefor get unstuck by backing up enough. However, it is not always the case that the wall is in front of the robot, and backing up could end up moving the robot into a wall. Instead, a better policy would be to turn and move away from the closest wall whenever the robot is stuck.\n\nSetup\n\n  Download the file (source code)\n  Unzip the file into the \\catkin_ws\\src directory\n  In \\catkin_ws, run this command to build\n\n\n1\ncatkin_make\n\n\nRun\n\n  Open a new terminal\n  In \\catkin_ws, run this command to source the bash file\n\n\n1\nsource devel/setup.bash\n\n\n\n  Run this command to launch the ros package\n\n\n1\nroslaunch src/rob456_project/launch/rob456_project.launch\n\n\n\n  Open a new terminal\n  In \\catkin_ws, run this command to source the bash file\n\n\n1\nsource devel/setup.bash\n\n\n\n  Run this command to launch the ros package\n\n\n1\nroslaunch src/nav_bundle/launch/nav_bundle.launch\n\n\n\n  When the world starts, in rviz, select '2D Nav Goal' and point to a closer cell that has been explored\n\n\nContributors\n\n\n  Lucas Frey lcsfrey\n  Mazen Alotaibi sudomaze\n  Daniel Boreham"

    },
  
    {

      "title"    : "Linux vs. FreeBSD vs. Windows",
      "url"      : "/projects/linux-vs-freebsd-vs-windows",
      "content"  : "Introduction\n\nThis paper presents a comparison between Linux, FreeBSD, and Windows in three areas: concurrency, I/O, and memory management. In addition, in each area, I will discussing about the differences and similarities between them.\n\nConcurrency Comparison\n\nIn this section, I will be discussing about processes, threads, CPU scheduling, and other related information that I have found interesting for each operating system based on my research.\n\nLinux\n\nEach process provides the resources needed to execute a program. A process has a virtual address space, executable code, open handles to system objects, a security context, a unique process identifier, environment variables, a priority class, minimum and maximum working set sizes, and at least one thread of execution. Each process is started with a single thread, often called the primary thread, but can create additional threads from any of its threads [1].\n\nTo create a process in Linux, we will need to use Fork() system call, which creates a new process, called the child process, from the exiting process, called the parent process. The child process has its own process ID (PID). Fork() takes no argument and return process ID. Fork() returns negative value if the process isn't created, zero if the child process is created, and positive value and a child process ID if Fork() returns from parent process. In addition, system call Fork() duplicate the same address space of the parent process and allocate to the child process. However, the child process doesn't inherit timer and semaphore adjustment from the parent process [2].\n\nThe following code sample demonstrates how to create a process in Linux [3]:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n#include &lt;unistd.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main( )\n{\n    pid_t child_pid;\n    child_pid = fork ( );                                    // Create a new child process;\n    if (child_pid &gt;= 0)                         \n    {\n        if (child_pid == 0)\n        {\n            printf (\"child process successfully created!!\\n\");\n            printf (\"child PID =  %d, parent PID = %d\\n\", getpid( ), getppid( ) );\n            exit(0);\n         }\n    }\n    else\n    {\n        perror(\"fork\");\n        exit(0);\n    }\n}\n\n\nThreads of execution, often shortened to threads, are the objects of activity within the process. Each thread includes a unique program counter, process stack, and set of processor registers. The kernel schedules individual threads, not processes. In traditional Unix systems, each process consists of one thread. In modern systems, however, multi-threaded programs consist of more than one thread are common [1].\n\nFreeBSD\n\nA process is a program in execution. Each process has an address space containing a mapping of its program’s object code and global variables, a set of kernel resources that it can name and on which it can operate using system calls, and at least one and possibly many threads that execute its code. Every process in the system is assigned a unique identifier termed the process identifier (PID). An PID is a common mechanism used by applications and by the kernel to reference processes and it is used by applications when the latter send a signal to a process and when receiving the exit status from a deceased process. There are two PIDs that are special important to to each process:  the PID of the process itself and the PID of the process’s parent process. A process structure contains information that must always remain resident in main memory, along with references to other structures that remain resident [4].\n\nEvery thread represents a virtual processor with a full context worth of register state and its own stack mapped into the address space. In addition, every thread running in the process has a corresponding kernel thread, with its own kernel stack that represents the user thread when it is executing in the kernel as a result of a system call, page fault, or signal delivery. The threads of a process operate in either user mode or kernel mode. In user mode, a thread executes application code with the machine in a non-privileged protection mode. Thread structure tracks information that needs to be resident only when the process is executing such as its kernel run-time stack. Both, process and thread, structures are allocated dynamically as part of process creation and are freed when the process is destroyed as it exits [4].\n\nThe FreeBSD timeshare scheduler uses a priority-based scheduling policy that is biased to favor interactive programs, such as text editors, over long-running batch-type jobs. Interactive programs tend to exhibit short bursts of computation followed by periods of inactivity or I/O. The scheduling policy initially assigns a high execution priority to each thread and allows that thread to execute for a fixed time slice [4].\n\nWindows\n\nA process is basically a program in execution. The execution of a process must progress in a sequential fashion. Each process is uniquely identified by a number called a process ID (PID). Similar to files, each process has one owner and group, and the owner and group permissions are used to determine which files and devices the process can open [5].\n\nIn addition, to create a process in Windows, we will need to use CreateProcess function. CreateProcess function runs independently of the creating process, and the following code sample demonstrates how to create a process [5]:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n#include &lt;windows.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;tchar.h&gt;\n\nvoid _tmain( int argc, TCHAR *argv[] )\n{\n    STARTUPINFO si;\n    PROCESS_INFORMATION pi;\n    ZeroMemory( &amp;si, sizeof(si) );\n    si.cb = sizeof(si);\n    ZeroMemory( &amp;pi, sizeof(pi) );\n    if( argc != 2 )\n    {\n        printf(\"Usage: %s [cmdline]\\n\", argv[0]);\n        return;\n    }\n    // Start the child process. \n    if( !CreateProcess( NULL,   // No module name (use command line)\n        argv[1],        // Command line\n        NULL,           // Process handle not inheritable\n        NULL,           // Thread handle not inheritable\n        FALSE,          // Set handle inheritance to FALSE\n        0,              // No creation flags\n        NULL,           // Use parent's environment block\n        NULL,           // Use parent's starting directory\n        &amp;si,            // Pointer to STARTUPINFO structure\n        &amp;pi )           // Pointer to PROCESS_INFORMATION structure\n    ) \n    {\n        printf( \"CreateProcess failed (%d).\\n\", GetLastError() );\n        return;\n    }\n    // Wait until child process exits.\n    WaitForSingleObject( pi.hProcess, INFINITE );\n    // Close process and thread handles.\n    CloseHandle( pi.hProcess );\n    CloseHandle( pi.hThread );\n}\n\n\nWindows implements a priority-driven, preemptive scheduling system, at least one of the highest priority ready threads always runs, with the caution that certain high-priority threads ready to run might be limited by the processors on which they might be allowed or preferred to run on, a phenomenon called processor affinity [6].\n\nGeneral Discussion\n\nFrom my research, they all have similar processes features and behaviors, and Windows' threads are similar to FreeBSD in the current model and the interface definition for Windows' threads are similar to Linux. In addition, FreeBSD and Windows have a similar CPU scheduling as they both use priority-queues. [1][2][4][5][6].\n\nIO Comparison\n\nIn this section, I will be discussing about I/O (block and character), data structures, algorithms, cryptography, I/O scheduling, types of devices, and other related information that I have found interesting for each operating system based on my research.\n\nFreeBSD\n\nThe basic model of the UNIX I/O system is a sequence of bytes that can be accessed either randomly or sequentially, and there aren't any access methods and control blocks in typical UNIX user process. Different programs expect various levels of structure, but the kernel doesn't impose structure on I/O. In addition, UNIX processes use a descriptor to reference I/O streams. Descriptors are small unsigned integers obtained from the open and socket system calls. Read and write system calls can be applied to descriptors to transfer data, and close system call can be used to dead-locate any descriptor. There are three types of descriptors, files, pipes, and sockets. Files are linear array bytes, has at least one name, exists until all its names are deleted explicitly, and no process holds a descriptor for it. Pipes are a linear array of bytes, no name, used as an I/O stream, it is unidirectional, and created by a pipe system call. Sockets are transient objects, used for interprocess communication, exists only as long as some process holds a descriptor referring to it, and created by a socket system call. Furthermore, hardware devices can be categorized as either block (structure) or character (unstructured). For block devices, they are typified by disks and magnetic tapes, the kernel supports read-modify-write-type buffering actions on block-oriented structured devices to allow latter to be read and written in a totally random byte addressed fashion, and the filesystems are created on block devices. For character devices, they are communication lines, raster plotters, and unbuffered magnetic tapes and disks, and are support large block I/O transfers [7].\n\nFor previous editions of stream I/O system, the stream I/O system was based on the UNIX character I/O system, which allows a user process to open a way terminal port and then to insert appropriated kernel-processing modules and the modules that are being processed by the network protocols can be inserted in the appreciated kernel-processing modules. In addition, stacking a terminal-processing module on top of a network-processing module allowed flexible and efficient implementation of the network viral terminals within the kernel. In newer editions of stream I/O system ,such as 18th edition which was adopted in System V. However, the design of the networking facilities for 4.2BSD changed its approach based on the socket interface and flexible multi-player network architecture, which allows a single system to support multiple sets of networking protocols with stream, datagram, and other types of access. In addition, the user application and the kernel operate independently of each other for security. In 4.4BSD, the kernel doesn't store I/O control blocks or other operating-system-related data structures in the application address space. Each user-level application is provided with an independent address space in which it executes its applications/processes. Moreover, the kernel makes most of the state changes invisible to the processes involved [7].\n\nFreeBSD supports two different disk encryption methods, GBDE and GELI, and both of the methods support different cryptographic algorithms that counter different threats. For GBDE, it is high-security (protecting the user as protecting the data), cryptographic key provided by the user, and when the key is lost, the data can't be accessed. On the other hand, GELI protects the data but doesn't protect the user, it uses FreeBSD's cryptographic device driver, and takes advantage of its transparently [8].\n\nWindows\n\nThe design goals for the Windows I/O system are to provide an abstraction of devices, both hardware and software to application with a selected features of the operating system, such as uniform security, high-performance asynchronous, high-level language support, etc. Windows I/O system is responsible for the connection between user model functionality, storage, and drivers with WDM WMI Routines, PnP Manager, Power Manager, and I/O Manager. For I/O Manager, it is the core of the Windows I/O system because it defines the order of the framework within which I/O requests are delivered to device drivers. Most I/O requests are represented as I/O Request Packet (IRP), which travels from one I/O system component to another. The design of Windows I/O system allows an individual application thread to manage multiple I/O requests concurrently [9].\n\nMoreover, I have found 4 interesting algorithms built within the driver structure, Initialization Routine, Opening Devices, IRP, and Completing an I/O Request. For the Initialization Routine, the I/O manager executes a driver's Initialization Routine when it loads the driver into the operating system. Then, the Initialization Routine fills in the system data structures to register the rest of the driver's routines with the I/O manager and performs any global driver initialization that is necessary. For the Opening Devices, a file object is in a kernel model data structure that represents a handle to a device, and this process allows synchronization and easy manipulation of the object files. For IRP, the IRP is where the I/O system stores information it needs to process an I/O request, so when a thread calls an I/O API, the I/O manager constructs an IRP to represent the operation as it progresses through the I/O system. For Completing an I/O Request, it starts when a driver calls IoCompleteRequest to inform the I/O manager that has completed process teh request specified in the IRP [9].\n\nI have found a good example[10] of how to use IoCompleteRequest in a Windows machine to implement Completing an I/O Request.\n\n1\n2\n3\n4\n5\n6\n7\nNTSTATUS CompleteRequest(PIRP Irp, NTSTATUS status, ULONG_PTR Information)\n{\n    Irp-&gt;IoStatus.Status = status;\n    Irp-&gt;IoStatus.Information = Information;\n    IoCompleteRequest(Irp, IO_NO_INCREMENT);\n    return status;\n}\n\n\nGeneral Discussion\n\nA comparison between FreeBSD, Linux, and Windows 2000, that FreeBSD and Linux have higher security compared to Windows 2000 because they are both open source and Windows 2000 is closed, which means the main developers need to detect errors in the system by themselve. However, FreeBSD has higher security than Linux beucase FreeBSD requires third parties verification of the system compared to Linux, which can accepts updates from anyone with minor verification. In addition, Windows 2000 is supported by most of device manufactures because its layered architecture and generic use of objects [11][12].\n\nTo sum up, it seems that FreeBSD has a Linux-like I/O system strcture compared to Windows which treats every file as an object. In addition, FreeBSD has higher security than Linux and Windows because FreeBSD has different methods to protect data. However, Windows is supported by most of device manufactures because its layered architecture and generic use of objects [7][8][9][11][12].\n\nMemory Management Comparison\n\nIn this section, I will be discussing about memory management in FreeBSD and Windows based on my research.\n\nFreeBSD\n\nBerkeley Software Distribution (BSD) kernel handles process scheduling, memory management, symmetric multi-processing, device drivers, etc. In addition, for memory management in general, each process has its own private address and each address space is divided into 3 logical segments: text, data, and stack. For the text segment, it is read-only, has initialized and uninitialized data portions of a program, and, in most machines, a process can change the size of its text segment only when the segment's contents are overlaid with data from the files system or when debugging in action. For the stack, it has application's run-time stack and makes a system call in most machines. Lastly, initial contents of the segments of a child process are duplicated from the segments of a parent process. Moreover, for memory management inside the kernel, kernel often does allocation of memory that are needed for only the duration of a single system call, but in a user process, such as short-term memory, would be allocated on the run-time stack. Kernel's memory isn't feasible to allocate even moderate-sized blocks of memory on it because the kernel has a limited run-time stack [7].\n\nFor memory management, kernel can't easily deal with memory allocation errors and often can't scheme. Therefore, getting the memory in the kernel is more complicated than in user-space. Moreover, kernel treats phsical pages as the basic unit of memory management and kernel represents every phsical page on the system with a struct page structure, which is defined in &lt;linux/mm_types.h&gt; [1].\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nstruct page {\n    unsigned long flags;\n    atomic_t _count;\n    atomic_t _mapcount;\n    unsigned long private;\n    struct address_space *mapping;\n    pgoff_t index;\n    struct list_head lru;\n    void *virtual;\n};\n\n\nThe kernel can't treat all pages as the same because the hardware limitation. Therefore, some pages can't be used for certain because of their physical address in memory. Hence, kernel uses the zones to group pages of similar properties. Linux partitions the system's pages into zones to have a pooling in place to satisfy allocations as needed. Although some allocations may require pages from a partiular zone, other allocations my pull from multiple zones. Each zone is represented by a struct zone, which is defined in &lt;linux/mmzone.h&gt; [1].\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\nstruct zone {\n    unsigned long watermark[NR_WMARK];\n    unsigned long lowmem_reserve[MAX_NR_ZONES];\n    struct per_cpu_pageset pageset[NR_CPUS];\n    spinlock_t lock;\n    struct free_area free_area[MAX_ORDER]\n    spinlock_t lru_lock;\n    struct zone_lru {\n        struct list_head list;\n        unsigned long nr_saved_scan;\n    } lru[NR_LRU_LISTS];\n    struct zone_reclaim_stat reclaim_stat;\n    unsigned long pages_scanned;\n    unsigned long flags;\n    atomic_long_t vm_stat[NR_VM_ZONE_STAT_ITEMS];\n    int prev_priority;\n    unsigned int inactive_ratio;\n    wait_queue_head_t *wait_table;\n    unsigned long wait_table_hash_nr_entries;\n    unsigned long wait_table_bits;\n    struct pglist_data *zone_pgdat;\n    unsigned long zone_start_pfn;\n    unsigned long spanned_pages;\n    unsigned long present_pages;\n    const char *name;\n};\n\n\nKmalloc() is similar to malloc() in user-space, but it is just a simple interface for obtaining kernel memory in byte-sized chunks and it can be used to allocate pages. For freeing pages, we can use kfree(), which is definded in &lt;linux/slab.h&gt;, kfree() frees a block of memory previously allocated with kmalloc() [1].\n\n1\n2\n3\n4\n5\n    buf = kmalloc(BUF_SIZE, GFP_ATOMIC);\n    if (!buf)\n    /* error allocating memory ! */\n    ...\n    kfree(buf);\n\n\nFree lists data structures are the default data structures in kernel. Due to the fact that allocating and freeing data structures is one of the most common operations inside any kernel has issues, slab layer is used to solve these issues. Slab layer acts as generic data structure-chaining layer and slab layer attempts to cache frequently used data structures as they tend to be allocated and freed often, prevent memory fragmentation, which is resulted from frequent allocation and deallocation, by cached free lists are arranged contiguously, and it has many other promises that slab layer attempts to provide [1].\n\nWindows\n\nThe memory manager in Windows implements virtual memory, provides a core set of services such as memory mapped files, copy-on-write memory, large memory support, and underlying support for the cache manager.The memory manager creates the two memory pools, non-paged pool and paged pool, that the system uses to allocate memory. Non-paged pool and paged pool are located in the region of the address space that is reserved for the system and mapped into the virtual address space of each process. For the non-paged pool, it consists of virtual memory addresses that are guaranteed to reside in physical memory as long as the corresponding kernel objects are allocated. For the paged pool, it consists of virtual memory that can be paged in and out of the system. To improve performance, systems with a single processor have three paged pools, and multiprocessor systems have five paged pools [5].\n\nIt seems that Windows uses VirtualAlloc() to use a page granularity, so using VirtualAlloc can result in higher memory usage and it allows you to specify additional options for memory allocation. In order to free pages, you need to use VirtualFree() [5].\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nLPVOID WINAPI VirtualAlloc(\n      _In_opt_ LPVOID lpAddress,\n      _In_     SIZE_T dwSize,\n      _In_     DWORD  flAllocationType,\n      _In_     DWORD  flProtect\n);\nBOOL WINAPI VirtualFree(\n      _In_ LPVOID lpAddress,\n      _In_ SIZE_T dwSize,\n      _In_ DWORD  dwFreeType\n);\n\n\nGeneral Discussion\n\nWindows and Linux has different memory management structures. In Windows, memory management uses tree data structures, uses cluster demand paging, brings 8 pages in memory simultaneously, and page replacements uses First In First Out (FIFO) algorithm. In the other hand, in Linux, memory management uses linked lists data stricture, uses demand paging with no pre-paging and it doesn't swap the entire process instead it uses a lazy swapper, swaps the necessary pages into memory only to avoid reading pages that won't be used, which decreases swap time and amount of physical memory required, and page replacement uses Least Recently Used (LRU) algorithm [13].\n\nFrom my research, it seems that Windows is built for commercial use due it's complex systems to handle large amount of data compared to linux and FreeBSD, and FreeBSD seems to follow most of Linux memory management style, but it is more stable than Linux by using different methods [1][5][7][13].\n\nConclusion\n\nTo conclude, I have discussed about the differences and similarity between Linux, FreeBSD, and Windows in these areas: concurrency, I/O, and memory management. Therefore, based on my research and understanding, I conclude that FreeBSD and Linux are an excellent operating systems because of their system simplicity compared to Windows. However, Windows complexity was made for a certain purpose, which is commercial use. In addition, FreeBSD seems to be more stable and secure than Linux. Other than that, all of the systems have similar general architecture and data flow, but they vary in the way they implement and process these parts.\n\nReferences\n\nR. Love,Linux Kernel Development, 3rd ed. Addison-Wesley Professional, 2010.\n\n\"Operating system-processes,\"Available at https://www.tutorialspoint.com/operatingsystem/osprocesses.htm(2018/10/19).\n\nA. Vara, \"How to create process in linux (part 10/15),\" Available at https://www.engineersgarage.com/tutorials/introduction-linux-part-1015.\n\nM. K. McKusick, G. Neville-Neil, and R. N. Watson,The Design and Implementation of the FreeBSD Operating System, 2nd ed. Addison-Wesley Professional, 2014.\n\n\"Memory management,\" Available at https://docs.microsoft.com/en-us/windows/desktop/memory/memory-management(2018/05/30).\n\nM. E. Russinovich, D. A. Solomon, and A. Ionescu,Windows Internals, Part 1: Covering Windows Server 2008 R2 and Windows 7,6th ed. Redmond, WA, USA: Microsoft Press, 2012.\n\nM. K. McKusick, K. Bostic, M. J. Karels, and J. S. Quarterman,The Design and Implementation of the 4.4BSD Operating System.Redwood City, CA, USA: Addison Wesley Longman Publishing Co., Inc., 1996.\n\nM. W. Lucas,Absolute Freebsd, 2Nd Edition, 2nd ed. San Francisco, CA, USA: No Starch Press, 2007.\n\nM. E. Russinovich, D. A. Solomon, and A. Ionescu,Windows Internals, Part 2: Covering Windows Server 2008 R2 and Windows 7(Windows Internals). Redmond, WA, USA: Microsoft Press, 2012.\n\nH. Haftmann, \"Completing i/o requests,\" Available at https://www-user.tu-chemnitz.de/∼heha/oneywdm/ch05d.htm.\n\nB. Bruce and M. Stokely, \"Freebsd vs. linux vs. windows 2000,\" Available at https://people.freebsd.org/∼murray/bsdflier.html.\n\nS. Hand, \"Operating systems,\" Available at https://www.cl.cam.ac.uk/teaching/1011/OpSystems/os1a-slides.pdf\n\nU. Essays, \"Compare the memory management of windows with linux,\" Available at https://www.ukessays.com/essays/engineering/compare-the-memory-management.php (2016/12/05)."

    },
  
    {

      "title"    : "Travelling Salesman Problem",
      "url"      : "/projects/travelling-salesman-problem",
      "content"  : "Description\n\nThis is a final report for analysis of solving the travelling salesman problem using multiple algorithms and the analysis of those algorithms.\n\nAlgorithms that Solve TSP\n\nBrute Force Search (Naive Algorithm)\n\nRun-time Analysis\n\n\\[O(n!)\\]\n\nPseudo-code\n\n\n    \n\\begin{algorithm}\n\\caption{Brute Force Search}\n\\begin{algorithmic}\n\\Procedure{BF}{$r$, $cititiesNotInRoute[1...n]$}\n    \\If {$citiesNotInRoute.length != 0$}\n        \\For{$i$ \\textbf{from} $0$ \\textbf{to} $citiesNotInRoute.length$}\n            \\State $cityRemoved = popFront(cititiesNotInRoute)$\n            \\State $newRoute = r$\n            \\State $push(newRoute, cityRemoved)$\n            \\State $BF(newRoute, cititiesNotInRoute)$\n            \\State $push(cititiesNotInRoute, cityRemoved)$\n        \\EndFor\n    \\EndIf\n    \\If {$skip == true$}\n        \\State $print(r)$\n    \\EndIf\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n\n\n\n\n\nDescription\n\nThis algorithm checks every vertices and every edges. Therefore, it is clear it will find the solution. The running time is $O(n!)$ because the starting vertex has $n-1$  edges to choose, next one has $n-2$  edges to choose, $…  n-1$  vertex has $1$ edge to choose. Therefore, by multiply every edges, Icould get the running time which is $(n-1)!$. Since it is clear $(n-1)! &lt;  n!$, I can say the running time is $O(n!)$.I choose this algorithm because it is the basic way to think about how to solve this problem. This algorithm is easy to make, but it is really slow. Therefore, this algorithm makes us to realize how important the algorithm is. Better algorithm makes way more faster program.\n\nHeld-Karp Algorithm (Dynamic Algorithm)\n\nRun-time Analysis\n\n\\[O(n^{2} \\times 2^{n})\\]\n\nPseudo-code\n\n\n    \n\\begin{algorithm}\n\\caption{Held-Karp Algorithm}\n\\begin{algorithmic}\n\\Procedure{HK}{$G$, $n$}\n    \\For{$k$ \\textbf{from} $2$ \\textbf{to} $n$}\n        \\State $C(\\{k\\},k)=d_{1, k}$\n    \\EndFor\n    \\For{$s$ \\textbf{from} $2$ \\textbf{to} $n-1$}\n        \\For{$all\\ S \\subseteq \\{2,...,n\\}, |S|=s$}\n            \\For{$all\\ k \\in S$}\n                \\State $\\{C(S,k)=min_{m \\neq k, m \\in S}[C(S-\\{k\\},m)+d_{m, k}]\\}$\n            \\EndFor\n        \\EndFor\n    \\EndFor\n    \\State $opt=min_{k \\neq 1}[C(\\{2, 3, ..., n\\}, k) + d_{k, 1}]$\n    \\State \\textbf{return} $opt$\n\\EndProcedure\n\\end{algorithmic}\n\\end{algorithm}\n\n\n\n\n\nDescription\n\nThis algorithm use dynamic algorithm to solve the problem. It first gets the distance between two vertices and save it to array. It is $O(n)$ steps. The next part is to find the minimum distance with small set of vertices. The for loop, for $s$ from $2$ to $n-1$ and for all $S$  in ${2, …, n}$, $|S| =  s$, is defining small set of vertices. The next for loop is the part that getting the minimum distance from the set of vertices. Each set has s  elements and it has to compare with s  different minimum candidates, it has $O(s^{2})$ running time. The first two loop, which define the set S, has running time with $SUM_{i}=2^{n-1} (C(n-1,i))$ because there are $C(n-1, i)$ number of combination for defining set with $i$  elements, and since it is from $2$  to $n-1$, it makes $SUM_{i}=2^{n-1} (C(n-1,i)) \\times  n^{2})$. Hence, it could be rewrite as $n^{2} \\times  SUM_{i}=2^{n-1} (C(n-1,i))$ $&lt;= n^{2} \\times  2^{n-1} =  \\frac{1}{2}  \\times  n^{2} \\times  2^{n}$ $=  O(2^{n} \\times  n^{2}$). I choose this algorithm because I learned dynamic programming and this algorithm use that concepts. This algorithm saves data into $C(S, n)$ and use it to find minimum distance. By this skill, this algorithm can find real answer with way more faster than the brute force method. However, it is still slow.\n\nK-Nearest Neighbor Algorithm (Approximation Algorithm)\n\nRun-time Analysis\n\n\\[O(n^{2})\\]\n\nCode\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\ndef Distance(a,b):\n    return int(round(math.sqrt((math.pow(a['i'] - b['i'],2))+(math.pow(a['j'] - b['j'],2)))))\n\ndef KNN(cities, inFile):\n    matrix = [[-1 for x in range(len(cities))] for y in range(len(cities))]\n    minLength = sys.maxsize\n    order = []\n    for x in range(len(cities)):\n        allCities = [z for z in cities]\n        route = []\n        route.append(allCities[x]['city'])\n        allCities.remove(allCities[x])\n        length = 0\n        while len(allCities) &gt; 0:\n            current = cities[route[len(route)-1]]\n            minDistance = sys.maxsize\n            minCity = -1\n            for y in range(len(allCities)):\n                currentDistance = matrix[current['city']][allCities[y]['city']]\n                if currentDistance == -1:\n                    currentDistance = Distance(current, allCities[y])\n                    matrix[current['city']][allCities[y]['city']] = currentDistance\n                    matrix[allCities[y]['city']][current['city']] = currentDistance\n                if currentDistance &lt; minDistance:\n                    minDistance = currentDistance\n                    minCity = allCities[y]\n            route.append(minCity['city'])\n            allCities.remove(minCity)\n            length += minDistance\n        currentDistance = matrix[cities[route[0]]['city']][cities[route[len(route)-1]]['city']]\n        if currentDistance == -1:\n            currentDistance = Distance(cities[route[0]], cities[route[len(route)-1]])\n            matrix[cities[route[0]]['city']][cities[route[len(route)-1]]['city']] = currentDistance\n            matrix[cities[route[len(route)-1]]['city']][cities[route[0]]['city']] = currentDistance\n        length += currentDistance\n        if length &lt; minLength:\n            minLength = length\n            order = [x for x in route]\n            WriteFileKNN(inFile, order, minLength)\n\n\nDescription\n\nThis algorithm is greedy algorithm that finds the vertex with minimum weight and choose it. Therefore, the first vertex has to check $n-1$ edges and choose the minimum. Second one has to check n-2 edges and choose the minimum. The $n-1$ vertex choose $1$ edges. Hence, the running time is $SUM\\ 1\\ TO\\ N-1\\ = (N-1)(N-2)/2 = O(N^2)$. I choose this algorithm because I found that this is the fastest. This algorithm is greedy algorithm that choose only the nearest vertex from the start vertex, and keep finding the nearest vertex from the chosen one. Since it is just checking the nearest, there is possibility to find the wrong answer. However, I found that this algorithm finds reasonable path, which means not huge different than true answer, and the power of this algorithm is this is super fast. It is only $O(n^2)$. Therefore, this algorithm will be good choice when I need the result really quickly, and\nit is ok to have small error. I used a nearest neighbor algorithm written in Java to get inspiration for my Python program,\nfound here: http://www.sanfoundry.com/java-program-implement-traveling-salesman-problem-using-nearest-neighbour-algorithm/. The program searches for the most optimal nearest neighbor route by using a brute-force wrapper for-loop to select each city as the starting point. The program is able to analyze each\ncity for the smaller list sizes, but for the larger ones it cannot process each city within 5 minutes, so that is why I have a section of code in the main section of the program to end the algorithm after 5 minutes. Each time the algorithm finds a new shorter route it is written to the output file, so this ensures that I am still able to have a valid result at the very beginning, well before the 5 minute time constraint is over.\n\nGenetic Algorithm (Approximation Algorithm)\n\nRun-time Analysis\n\n\\[O(T \\times n_{0} \\times n^{2})\\]\n\nwhere $T$ is the number of outer iteration, $n_{0}$ is the initial size of the population, and $n$ is the number of cities.\n\nCode\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\nclass City:\n    def __init__(self, id, x, y):\n        self.id = id\n        self.x = x\n        self.y = y\n    \n    def distance(self, city):\n        # xDis = self.x - city.x\n        # yDis = self.y - city.y\n        # distance = np.sqrt((xDis ** 2) + (yDis ** 2))\n        return int(round(math.sqrt((math.pow(self.x - city.x,2))+(math.pow(self.y - city.y,2)))))\n    \n    def __repr__(self):\n        return \"(\" + str(self.x) + \",\" + str(self.y) + \")\"\n\nclass Fitness:\n    def __init__(self, route):\n        self.route = route\n        self.distance = 0\n        self.fitness= 0.0\n    \n    def routeDistance(self):\n        if self.distance ==0:\n            pathDistance = 0\n            for i in range(0, len(self.route)):\n                fromCity = self.route[i]\n                toCity = None\n                if i + 1 &lt; len(self.route):\n                    toCity = self.route[i + 1]\n                else:\n                    toCity = self.route[0]\n                pathDistance += fromCity.distance(toCity)\n            self.distance = pathDistance\n        return self.distance\n    \n    def routeFitness(self):\n        if self.fitness == 0:\n            self.fitness = 1 / float(self.routeDistance())\n        return self.fitness\ndef createRoute(cityList):\n    route = random.sample(cityList, len(cityList))\n    return route\ndef initialPopulation(popSize, cityList):\n    population = []\n\n    for i in range(0, popSize):\n        population.append(createRoute(cityList))\n    return population\ndef rankRoutes(population):\n    fitnessResults = {}\n    for i in range(0,len(population)):\n        fitnessResults[i] = Fitness(population[i]).routeFitness()\n    return sorted(fitnessResults.items(), key = operator.itemgetter(1), reverse = True)\ndef selection(popRanked, eliteSize):\n    selectionResults = []\n    df = pd.DataFrame(np.array(popRanked), columns=[\"Index\",\"Fitness\"])\n    df['cum_sum'] = df.Fitness.cumsum()\n    df['cum_perc'] = 100*df.cum_sum/df.Fitness.sum()\n    \n    for i in range(0, eliteSize):\n        selectionResults.append(popRanked[i][0])\n    for i in range(0, len(popRanked) - eliteSize):\n        pick = 100*random.random()\n        for i in range(0, len(popRanked)):\n            if pick &lt;= df.iat[i,3]:\n                selectionResults.append(popRanked[i][0])\n                break\n    return selectionResults\ndef matingPool(population, selectionResults):\n    matingpool = []\n    for i in range(0, len(selectionResults)):\n        index = selectionResults[i]\n        matingpool.append(population[index])\n    return matingpool\ndef breed(parent1, parent2):\n    child = []\n    childP1 = []\n    childP2 = []\n    \n    geneA = int(random.random() * len(parent1))\n    geneB = int(random.random() * len(parent1))\n    \n    startGene = min(geneA, geneB)\n    endGene = max(geneA, geneB)\n\n    for i in range(startGene, endGene):\n        childP1.append(parent1[i])\n        \n    childP2 = [item for item in parent2 if item not in childP1]\n\n    child = childP1 + childP2\n    return child\ndef breedPopulation(matingpool, eliteSize):\n    children = []\n    length = len(matingpool) - eliteSize\n    pool = random.sample(matingpool, len(matingpool))\n\n    for i in range(0,eliteSize):\n        children.append(matingpool[i])\n    \n    for i in range(0, length):\n        child = breed(pool[i], pool[len(matingpool)-i-1])\n        children.append(child)\n    return children\ndef mutate(individual, mutationRate):\n    for swapped in range(len(individual)):\n        if(random.random() &lt; mutationRate):\n            swapWith = int(random.random() * len(individual))\n            \n            city1 = individual[swapped]\n            city2 = individual[swapWith]\n            \n            individual[swapped] = city2\n            individual[swapWith] = city1\n    return individual\ndef mutatePopulation(population, mutationRate):\n    mutatedPop = []\n    \n    for ind in range(0, len(population)):\n        mutatedInd = mutate(population[ind], mutationRate)\n        mutatedPop.append(mutatedInd)\n    return mutatedPop\ndef nextGeneration(currentGen, eliteSize, mutationRate):\n    popRanked = rankRoutes(currentGen)\n    selectionResults = selection(popRanked, eliteSize)\n    matingpool = matingPool(currentGen, selectionResults)\n    children = breedPopulation(matingpool, eliteSize)\n    nextGeneration = mutatePopulation(children, mutationRate)\n    return nextGeneration\n\ndef GA(inFile, population, popSize, eliteSize, mutationRate, generations):\n    pop = initialPopulation(popSize, population)\n    # print(\"Initial distance: \" + str(1 / rankRoutes(pop)[0][1]))\n    \n    for i in range(0, generations):\n        pop = nextGeneration(pop, eliteSize, mutationRate)\n    \n    # print(\"Final distance: \" + str(1 / rankRoutes(pop)[0][1]))\n    bestRouteIndex = rankRoutes(pop)[0][0]\n    bestRoute = pop[bestRouteIndex]\n    WriteFileGA(inFile, bestRoute, 1 / rankRoutes(pop)[0][1])\n\n\nDescription\n\nThe genetic algorithm seems to solve different kind of problems pretty well, such as error detection, so I have thought to give it a try to solve the TSP. The implementation of the algorithm is extremely hard compared to KNN, so I need to refer to some online resource to build the algorithm on Python, the resource is found: https://towardsdatascience.com/evolution-of-a-salesman-a-complete-genetic-algorithm-tutorial-for-python-6fe5d2b3ca35. The algorithm starts with a population, a set of solutions, and every population another new population is generated to give better solutions, so as the depth of the population increases the algorithm should give better solutions in theory.\n\nTesting\n\nIn order to test that my program was actually producing valid results we used the supplied tsp-verifier.py program on each of my output routes. Each result was found to be valid.\n\nIt seems that the K-Nearest Neighbor (KNN) algorithm give better results in matter of approximation of path took and speed compared to Genetic Algorithm (GA) in all cases when time is the limitation. However, as the complexity of the graph increases and there isn't no time limits, the Genetic Algorithm can finish faster with higher approximation to the optimal path when the threshold to stop is set, compared to the KNN which takes almost 2 times longer on average to reach the same optimal path results.\n\nMy best results when testing where Test 1, 2, 4, and 5 when using KNN, and GA failed in most cases besides Test 6 and 7, which gave the same results as KNN at the same time.\n\nPlease view the next page to look into all of the results.\n\n\n  \n    \n       \n      Optimal path length\n      Predicted path length\n      Ratio\n    \n  \n  \n    \n      KNN\n      108159\n      130921\n      1.21\n    \n    \n      GA\n      108159\n      337541\n      3.12\n    \n  \n\n\n\n\n\n  \n    \n       \n      Optimal path length\n      Predicted path length\n      Ratio\n    \n  \n  \n    \n      KNN\n      2579\n      2975\n      1.15\n    \n    \n      GA\n      2579\n      27639\n      10.71\n    \n  \n\n\n\n\n\n  \n    \n       \n      Optimal path length\n      Predicted path length\n      Ratio\n    \n  \n  \n    \n      KNN\n      1573084\n      1936941\n      1.23\n    \n    \n      GA\n      1573084\n      1934200\n      1.22\n    \n  \n\n\n\n\n\n  \n    \n       \n      Predicted path length\n      Time took\n    \n  \n  \n    \n      KNN\n      5911\n      0.014127969741821289\n    \n    \n      GA\n      10488\n      14.512681007385254}\n    \n  \n\n\n\n\n\n  \n    \n       \n      Predicted path length\n      Time took\n    \n  \n  \n    \n      KNN\n      8011\n      0.11811113357543945\n    \n    \n      GA\n      32837\n      18.30189299583435\n    \n  \n\n\n\n\n\n  \n    \n       \n      Predicted path length\n      Time took\n    \n  \n  \n    \n      KNN\n      14826\n      1.3867180347442627\n    \n    \n      GA\n      103387\n      34.44625997543335\n    \n  \n\n\n\n\n\n  \n    \n       \n      Predicted path length\n      Time took\n    \n  \n  \n    \n      KNN\n      19711\n      12.897594213485718\n    \n    \n      GA\n      220727\n      73.32604813575745\n    \n  \n\n\n\n\n\n  \n    \n       \n      Predicted path length\n      Time took\n    \n  \n  \n    \n      KNN\n      27128\n      123.83275985717773\n    \n    \n      GA\n      465770\n      200.42861986160278\n    \n  \n\n\n\n\n\n  \n    \n       \n      Predicted path length\n      Time took\n    \n  \n  \n    \n      KNN\n      39834\n      299.0716700553894\n    \n    \n      GA\n      39834\n      299.00313663482666\n    \n  \n\n\n\n\n\n  \n    \n       \n      Predicted path length\n      Time took\n    \n  \n  \n    \n      KNN\n      62110\n      299.6045079231262\n    \n    \n      GA\n      62110\n      299.00823521614075"

    },
  
    {

      "title"    : "ReplaceMe",
      "url"      : "/projects/replaceme",
      "content"  : "Problem Statement\n\nI don't want to share my beautiful face on stream. However, I want to have a different representation of my face on stream in real-time that chat can change when they redeem their points on stream.\n\nI have found this interesting program, FaceRig, by Holotech Studios that allows an animated character with a face to simulate a human's face motion by mapping the human's face features to the animated character.\n\n\n\n\n  \n\n\n\nAs I want the animated character to be updated based on viewers' choice. I will need to build an API to allow the update to happen.\n\nI think there are few problems to tackle are:\n\n  Building face recognition system.\n  Compiling/finding a 3D model of an animated character.\n  Mapping the face recognition system with the 3D model.\n  Enabling the ability to update the 3D model with different animated characters from a script.\n  Building an API to allow the update from different machines on different networks.\n  Building a bot for the connectivity between the program API and Twitch API.\n\n\nPipeline\n\nI think the expected pipeline will include the following:\n\n  Computer Vision System\n    \n      Face Recognition\n      3D animated character\n    \n  \n  API\n  Web App\n  Twitch connectivity\n    \n      Twitch API\n      Nightbot\n    \n  \n\n\n\n\n    Figure 1: Expected pipeline\n\n\nNotes\n\nPlan\n\nI have found this project on Reddit by yemount. It seems that the project delivers what I am trying to accomplish in this project but using pose-estimate (detecting the entire body) and 2D image.\n\n###\n\nReferences\n\n[1]"

    },
  

  
]